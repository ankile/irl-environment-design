{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "curr_dir = os.path.split(os.getcwd())[1]\n",
    "if curr_dir != \"irl-environment-design\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.make_environment import (\n",
    "    transition_matrix,\n",
    "    Environment,\n",
    "    insert_walls_into_T,\n",
    ")\n",
    "\n",
    "from src.utils.constants import GenParamTuple# candidate_environments_args[\"n_environments\"] = 50\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=160, precision=2)\n",
    "\n",
    "from src.utils.environment_design import EnvironmentDesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make true environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliff World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, M = 4, 8\n",
    "\n",
    "# agent_gamma = np.array(0.7)\n",
    "# p_true= np.array(0.9)\n",
    "# reward_true = np.array(0.8)\n",
    "\n",
    "# agent_R = np.zeros((N, M))\n",
    "# agent_R[0,1] = -1\n",
    "# agent_R[0,2] = -1\n",
    "# agent_R[0,3] = -1\n",
    "# agent_R[0,4] = -1\n",
    "# agent_R[0,5] = -1\n",
    "# agent_R[0,6] = -1\n",
    "# agent_R[0,7] = reward_true\n",
    "# agent_R = agent_R.flatten()\n",
    "\n",
    "# goal_states = np.where(agent_R != 0)[0]\n",
    "\n",
    "# T = transition_matrix(N, M, p_true, absorbing_states=goal_states)\n",
    "\n",
    "# #Define custom functions to generate reward, transition and gamma.\n",
    "# def custom_transition_func(p):\n",
    "\n",
    "#     _T = transition_matrix(N=4, M=8, p=p, absorbing_states=goal_states)\n",
    "#     return _T\n",
    "\n",
    "# def custom_gamma_func(gamma):\n",
    "#     return gamma\n",
    "\n",
    "# def custom_reward_func(reward):\n",
    "#     agent_R = np.zeros((4, 8))\n",
    "#     agent_R[0,1] = -1\n",
    "#     agent_R[0,2] = -1\n",
    "#     agent_R[0,3] = -1\n",
    "#     agent_R[0,4] = -1\n",
    "#     agent_R[0,5] = -1\n",
    "#     agent_R[0,6] = -1\n",
    "#     agent_R[0,7] = reward\n",
    "#     return agent_R.flatten()\n",
    "\n",
    "# #Create parameter ranges\n",
    "# resolution = 15\n",
    "# p_range = np.linspace(0.7, 0.95, resolution)\n",
    "# gamma_range = np.linspace(0.5, 0.95, resolution)\n",
    "# R_range = np.linspace(0.7, 0.95, resolution)\n",
    "\n",
    "# gamma_range = gamma_range.reshape(1, resolution)\n",
    "# p_range = p_range.reshape(1, resolution)\n",
    "# R_range = R_range.reshape(1, resolution)\n",
    "\n",
    "\n",
    "\n",
    "# p_true = p_true.reshape(1, 1)\n",
    "# agent_gamma = agent_gamma.reshape(1, 1)\n",
    "# reward_true = reward_true.reshape(1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# true_params = GenParamTuple(T = p_true, gamma=agent_gamma, R=reward_true)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cliff = Environment(\n",
    "#     N=N,\n",
    "#     M=M,\n",
    "#     reward_function = custom_reward_func,\n",
    "#     transition_function=custom_transition_func,\n",
    "#     gamma = custom_gamma_func,\n",
    "#     wall_states=[],\n",
    "#     start_state=0,\n",
    "#     goal_states=goal_states\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Setup\n",
    "N, M = 7,7\n",
    "\n",
    "\n",
    "\n",
    "# Start by making the agent we want to learn the parameters of\n",
    "agent_gamma = np.array(0.75)\n",
    "p_true= np.array(0.9)\n",
    "big_reward_true = np.array(0.5)\n",
    "\n",
    "agent_R = np.zeros((N, M))\n",
    "agent_R[N-1, 0] = 0.1\n",
    "agent_R[N-1, M-1] = big_reward_true\n",
    "agent_R = agent_R.flatten()\n",
    "\n",
    "goal_states = np.where(agent_R != 0)[0]\n",
    "\n",
    "\n",
    "# wall_states = [14] #TODO: why do we need this\n",
    "wall_states = []\n",
    "\n",
    "T_true = transition_matrix(N, M, p=p_true, absorbing_states=goal_states)\n",
    "T_True = insert_walls_into_T(T=T_true, wall_indices=wall_states)\n",
    "\n",
    "\n",
    "#Define custom functions to generate reward, transition and gamma.\n",
    "def custom_transition_func(p):\n",
    "\n",
    "    _T = transition_matrix(N=7, M=7, p=p, absorbing_states=goal_states)\n",
    "    _T = insert_walls_into_T(T=_T, wall_indices=wall_states)\n",
    "    return _T\n",
    "\n",
    "def custom_gamma_func(gamma):\n",
    "    return gamma\n",
    "\n",
    "def custom_reward_func(big_reward):\n",
    "    reward_func = np.zeros((N, M))\n",
    "    reward_func[N-1, 0] = 0.1\n",
    "    reward_func[N-1, M-1] = big_reward\n",
    "    return reward_func.flatten()\n",
    "\n",
    "\n",
    "#Create parameter ranges\n",
    "resolution = 20\n",
    "p_range = np.linspace(0.7, 0.95, resolution)\n",
    "gamma_range = np.linspace(0.7, 0.95, resolution)\n",
    "R_range = np.linspace(0.3, 0.95, resolution)\n",
    "\n",
    "\n",
    "gamma_range = gamma_range.reshape(1, resolution)\n",
    "p_range = p_range.reshape(1, resolution)\n",
    "R_range = R_range.reshape(1, resolution)\n",
    "\n",
    "p_true = p_true.reshape(1, 1)\n",
    "agent_gamma = agent_gamma.reshape(1, 1)\n",
    "big_reward_true = big_reward_true.reshape(1, 1)\n",
    "\n",
    "\n",
    "\n",
    "true_params = GenParamTuple(T = p_true, gamma=agent_gamma, R=big_reward_true)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "big_small = Environment(\n",
    "    N=N,\n",
    "    M=M,\n",
    "    reward_function = custom_reward_func,\n",
    "    transition_function=custom_transition_func,\n",
    "    gamma = custom_gamma_func,\n",
    "    wall_states=wall_states,\n",
    "    start_state=1,\n",
    "    goal_states=goal_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated parameter mesh of shape:  (20, 20)\n"
     ]
    }
   ],
   "source": [
    "env_design = EnvironmentDesign(base_environment=big_small, \n",
    "                               user_params=true_params, \n",
    "                               learn_what = [\"gamma\", \"T\"],\n",
    "                               parameter_ranges_R=R_range,\n",
    "                               parameter_ranges_gamma=gamma_range,\n",
    "                               parameter_ranges_T=p_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started episode 0.\n",
      "Finished episode 0.\n",
      "Started episode 1.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78092/2296073164.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  reward_func[N-1, M-1] = big_reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior_dist: [[-20.3  -20.28 -20.27 -20.27 -20.27 -20.29 -20.32 -20.35 -20.4  -20.46 -20.53 -20.61 -20.7  -20.81 -20.93 -21.06 -21.2  -21.35 -21.5  -21.66]\n",
      " [-20.14 -20.12 -20.12 -20.12 -20.13 -20.16 -20.19 -20.24 -20.3  -20.37 -20.45 -20.54 -20.65 -20.77 -20.9  -21.04 -21.19 -21.33 -21.46 -21.58]\n",
      " [-19.97 -19.96 -19.96 -19.97 -19.99 -20.03 -20.07 -20.13 -20.2  -20.28 -20.38 -20.5  -20.62 -20.75 -20.88 -21.01 -21.13 -21.23 -21.31 -21.38]\n",
      " [-19.8  -19.8  -19.8  -19.82 -19.86 -19.9  -19.96 -20.04 -20.13 -20.24 -20.35 -20.48 -20.6  -20.71 -20.82 -20.91 -21.   -21.11 -21.27 -21.49]\n",
      " [-19.63 -19.63 -19.65 -19.69 -19.74 -19.81 -19.9  -20.   -20.11 -20.22 -20.34 -20.45 -20.55 -20.66 -20.78 -20.94 -21.16 -21.43 -21.75 -22.11]\n",
      " [-19.46 -19.49 -19.53 -19.6  -19.68 -19.78 -19.89 -20.   -20.11 -20.23 -20.34 -20.47 -20.63 -20.85 -21.11 -21.42 -21.78 -22.17 -22.61 -23.07]\n",
      " [-19.35 -19.41 -19.49 -19.58 -19.69 -19.8  -19.92 -20.04 -20.18 -20.34 -20.55 -20.81 -21.12 -21.47 -21.85 -22.28 -22.74 -23.24 -23.78 -24.35]\n",
      " [-19.31 -19.41 -19.52 -19.63 -19.76 -19.9  -20.07 -20.27 -20.53 -20.82 -21.16 -21.54 -21.96 -22.42 -22.92 -23.45 -24.02 -24.62 -25.26 -25.94]\n",
      " [-19.36 -19.49 -19.63 -19.8  -20.   -20.25 -20.54 -20.87 -21.24 -21.66 -22.11 -22.61 -23.14 -23.7  -24.31 -24.95 -25.62 -26.33 -27.08 -27.85]\n",
      " [-19.54 -19.73 -19.97 -20.25 -20.57 -20.94 -21.35 -21.81 -22.3  -22.83 -23.4  -24.   -24.64 -25.32 -26.04 -26.79 -27.57 -28.39 -29.24 -30.12]\n",
      " [-19.95 -20.27 -20.63 -21.04 -21.49 -21.98 -22.52 -23.09 -23.7  -24.35 -25.04 -25.76 -26.52 -27.32 -28.15 -29.01 -29.91 -30.83 -31.79 -32.78]\n",
      " [-20.71 -21.16 -21.65 -22.19 -22.77 -23.39 -24.05 -24.75 -25.49 -26.26 -27.07 -27.92 -28.8  -29.72 -30.66 -31.64 -32.66 -33.7  -34.77 -35.87]\n",
      " [-21.84 -22.43 -23.06 -23.73 -24.45 -25.21 -26.01 -26.84 -27.71 -28.62 -29.56 -30.53 -31.53 -32.57 -33.64 -34.74 -35.88 -37.04 -38.23 -39.44]\n",
      " [-23.38 -24.12 -24.91 -25.73 -26.59 -27.5  -28.44 -29.41 -30.42 -31.46 -32.54 -33.64 -34.78 -35.95 -37.15 -38.38 -39.63 -40.92 -42.23 -43.56]\n",
      " [-25.42 -26.32 -27.27 -28.25 -29.27 -30.33 -31.42 -32.54 -33.7  -34.88 -36.1  -37.34 -38.62 -39.92 -41.25 -42.61 -44.   -45.41 -46.84 -48.3 ]\n",
      " [-28.04 -29.11 -30.23 -31.38 -32.57 -33.79 -35.04 -36.32 -37.63 -38.96 -40.33 -41.72 -43.13 -44.57 -46.04 -47.53 -49.05 -50.59 -52.15 -53.72]\n",
      " [-31.35 -32.61 -33.91 -35.24 -36.61 -38.   -39.41 -40.85 -42.32 -43.81 -45.33 -46.87 -48.43 -50.01 -51.61 -53.24 -54.88 -56.55 -58.23 -59.92]\n",
      " [-35.5  -36.96 -38.46 -39.97 -41.52 -43.09 -44.67 -46.28 -47.91 -49.56 -51.23 -52.91 -54.62 -56.34 -58.08 -59.83 -61.61 -63.39 -65.18 -66.99]\n",
      " [-40.68 -42.35 -44.04 -45.76 -47.49 -49.23 -50.99 -52.76 -54.55 -56.35 -58.17 -60.   -61.84 -63.7  -65.57 -67.45 -69.34 -71.23 -73.13 -75.03]\n",
      " [-47.14 -49.02 -50.92 -52.82 -54.73 -56.65 -58.57 -60.5  -62.44 -64.38 -66.33 -68.29 -70.26 -72.24 -74.22 -76.22 -78.21 -80.21 -82.2  -84.18]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.7588677297415778, 0.7729220166851547]\n",
      "Computed Region of Interest. Size = 0.26\n",
      "Region of interest:  [140 120 160 121 141 100 122 101 161 142 102 180 123 103  80  81 162 143  82 104  83 124 181  84 144 105  61  60 163 125  62  85  63  64 106  86 145  65 126\n",
      " 200  41  42  66 182  40  43  44  87 107 164  45  67 127 146  46  88 108  22  23  21  47  68  24  20  25 128  26  48  89 109  69  27 165 183   3   2 201   4\n",
      " 147   1  49   5  28   0   6 110  90 129   7  70  29  50   8  30  91   9 111  71  51 148  10 166]\n",
      "Updated parameter mesh of shape:  (102, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.7  0.74]\n",
      " [0.7  0.75]\n",
      " [0.7  0.77]\n",
      " [0.7  0.78]\n",
      " [0.7  0.79]\n",
      " [0.7  0.81]\n",
      " [0.7  0.82]\n",
      " [0.7  0.83]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.71 0.73]\n",
      " [0.71 0.74]\n",
      " [0.71 0.75]\n",
      " [0.71 0.77]\n",
      " [0.71 0.78]\n",
      " [0.71 0.79]\n",
      " [0.71 0.81]\n",
      " [0.71 0.82]\n",
      " [0.71 0.83]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.73 0.73]\n",
      " [0.73 0.74]\n",
      " [0.73 0.75]\n",
      " [0.73 0.77]\n",
      " [0.73 0.78]\n",
      " [0.73 0.79]\n",
      " [0.73 0.81]\n",
      " [0.73 0.82]\n",
      " [0.73 0.83]\n",
      " [0.73 0.84]\n",
      " [0.74 0.7 ]\n",
      " [0.74 0.71]\n",
      " [0.74 0.73]\n",
      " [0.74 0.74]\n",
      " [0.74 0.75]\n",
      " [0.74 0.77]\n",
      " [0.74 0.78]\n",
      " [0.74 0.79]\n",
      " [0.74 0.81]\n",
      " [0.74 0.82]\n",
      " [0.74 0.83]\n",
      " [0.74 0.84]\n",
      " [0.75 0.7 ]\n",
      " [0.75 0.71]\n",
      " [0.75 0.73]\n",
      " [0.75 0.74]\n",
      " [0.75 0.75]\n",
      " [0.75 0.77]\n",
      " [0.75 0.78]\n",
      " [0.75 0.79]\n",
      " [0.75 0.81]\n",
      " [0.75 0.82]\n",
      " [0.75 0.83]\n",
      " [0.75 0.84]\n",
      " [0.77 0.7 ]\n",
      " [0.77 0.71]\n",
      " [0.77 0.73]\n",
      " [0.77 0.74]\n",
      " [0.77 0.75]\n",
      " [0.77 0.77]\n",
      " [0.77 0.78]\n",
      " [0.77 0.79]\n",
      " [0.77 0.81]\n",
      " [0.77 0.82]\n",
      " [0.77 0.83]\n",
      " [0.77 0.84]\n",
      " [0.78 0.7 ]\n",
      " [0.78 0.71]\n",
      " [0.78 0.73]\n",
      " [0.78 0.74]\n",
      " [0.78 0.75]\n",
      " [0.78 0.77]\n",
      " [0.78 0.78]\n",
      " [0.78 0.79]\n",
      " [0.78 0.81]\n",
      " [0.78 0.82]\n",
      " [0.79 0.7 ]\n",
      " [0.79 0.71]\n",
      " [0.79 0.73]\n",
      " [0.79 0.74]\n",
      " [0.79 0.75]\n",
      " [0.79 0.77]\n",
      " [0.79 0.78]\n",
      " [0.79 0.79]\n",
      " [0.79 0.81]\n",
      " [0.81 0.7 ]\n",
      " [0.81 0.71]\n",
      " [0.81 0.73]\n",
      " [0.81 0.74]\n",
      " [0.81 0.75]\n",
      " [0.81 0.77]\n",
      " [0.81 0.78]\n",
      " [0.82 0.7 ]\n",
      " [0.82 0.71]\n",
      " [0.82 0.73]\n",
      " [0.82 0.74]\n",
      " [0.83 0.7 ]\n",
      " [0.83 0.71]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'RRDDDDRDRDR': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 2, 3, 10, 17, 24, 31, 32, 39, 40, 47, 48]})\n",
      "Cover:  {0: 0.2525, 1: 0.7475}\n",
      "Iteration:  1\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.  -0.  -0.   0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.4075, 1: 0.5925}\n",
      "Iteration:  2\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.4375, 1: 0.5625}\n",
      "Iteration:  3\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Finished BM Search. Entropy: 0.6853142072764582. Max Ent possible: 0.6931471805599453. Cover: {0: 0.4375, 1: 0.5625}. Behaviors: {0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]}\n",
      "Behavior map:  ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Maximum Entropy Reward Update:  [ 0.  0. -0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0. -0. -0.\n",
      " -0. -0. -0.  0.  0.  0.  0.  0. -0. -0.]\n",
      "Finished episode 1.\n",
      "Started episode 2.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n",
      "posterior_dist: [[-34.26 -34.2  -34.15 -34.11 -34.09 -34.07 -34.07 -34.09 -34.11 -34.16 -34.21   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-34.12 -34.07 -34.04 -34.01 -34.   -34.01 -34.02 -34.05 -34.09 -34.15 -34.22   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-33.99 -33.96 -33.94 -33.94 -33.94 -33.96 -33.99 -34.04 -34.1  -34.18 -34.28 -34.39   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-33.89 -33.88 -33.88 -33.89 -33.91 -33.95 -34.01 -34.08 -34.18 -34.29 -34.41 -34.54   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-33.82 -33.83 -33.85 -33.88 -33.94 -34.02 -34.12 -34.24 -34.36 -34.49 -34.6  -34.7    -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-33.8  -33.84 -33.9  -33.99 -34.1  -34.22 -34.35 -34.48 -34.6  -34.69 -34.77 -34.85   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-33.89 -33.98 -34.11 -34.24 -34.38 -34.52 -34.65 -34.76 -34.87 -35.     -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-34.14 -34.3  -34.46 -34.61 -34.76 -34.91 -35.06 -35.27 -35.56   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-34.56 -34.74 -34.93 -35.12 -35.35 -35.64 -36.01   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-35.14 -35.4  -35.71 -36.09   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-36.12 -36.58   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.7438767352282182, 0.7585241562497747]\n",
      "Computed Region of Interest. Size = 0.16\n",
      "Region of interest:  [100  80  81 101  82  62  61  83  63 120  60 102  64  43  84  44  42  65  45  41 121 103  46  40  24  25  66  23  85  26  22  47  27  21   6   5  67   4   7\n",
      "  28 104  48 122   3   8  20  86 140   2  29   9  68  49   1  10 105  30  87 123   0  50  69 141 106  88]\n",
      "Updated parameter mesh of shape:  (65, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.7  0.74]\n",
      " [0.7  0.75]\n",
      " [0.7  0.77]\n",
      " [0.7  0.78]\n",
      " [0.7  0.79]\n",
      " [0.7  0.81]\n",
      " [0.7  0.82]\n",
      " [0.7  0.83]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.71 0.73]\n",
      " [0.71 0.74]\n",
      " [0.71 0.75]\n",
      " [0.71 0.77]\n",
      " [0.71 0.78]\n",
      " [0.71 0.79]\n",
      " [0.71 0.81]\n",
      " [0.71 0.82]\n",
      " [0.71 0.83]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.73 0.73]\n",
      " [0.73 0.74]\n",
      " [0.73 0.75]\n",
      " [0.73 0.77]\n",
      " [0.73 0.78]\n",
      " [0.73 0.79]\n",
      " [0.73 0.81]\n",
      " [0.73 0.82]\n",
      " [0.73 0.83]\n",
      " [0.74 0.7 ]\n",
      " [0.74 0.71]\n",
      " [0.74 0.73]\n",
      " [0.74 0.74]\n",
      " [0.74 0.75]\n",
      " [0.74 0.77]\n",
      " [0.74 0.78]\n",
      " [0.74 0.79]\n",
      " [0.74 0.81]\n",
      " [0.74 0.82]\n",
      " [0.75 0.7 ]\n",
      " [0.75 0.71]\n",
      " [0.75 0.73]\n",
      " [0.75 0.74]\n",
      " [0.75 0.75]\n",
      " [0.75 0.77]\n",
      " [0.75 0.78]\n",
      " [0.75 0.79]\n",
      " [0.75 0.81]\n",
      " [0.77 0.7 ]\n",
      " [0.77 0.71]\n",
      " [0.77 0.73]\n",
      " [0.77 0.74]\n",
      " [0.77 0.75]\n",
      " [0.77 0.77]\n",
      " [0.77 0.78]\n",
      " [0.78 0.7 ]\n",
      " [0.78 0.71]\n",
      " [0.78 0.73]\n",
      " [0.78 0.74]\n",
      " [0.79 0.7 ]\n",
      " [0.79 0.71]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'RRDDDDRDRDR': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 2, 3, 10, 17, 24, 31, 32, 39, 40, 47, 48]})\n",
      "Cover:  {0: 0.4, 1: 0.6}\n",
      "Iteration:  1\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.725, 1: 0.275}\n",
      "Iteration:  2\n",
      "Reward Function:  [ 0.00e+00  0.00e+00 -2.01e-03 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03\n",
      "  0.00e+00 -2.00e-03 -2.00e-03  0.00e+00  0.00e+00  0.00e+00  2.01e-03 -6.02e-05 -6.02e-05 -2.06e-03 -2.07e-03 -6.90e-05  1.02e-01  2.08e-03  0.00e+00\n",
      "  0.00e+00  0.00e+00 -2.08e-03  4.98e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6775, 1: 0.3225}\n",
      "Iteration:  3\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.  -0.  -0.   0.   0.1  0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.64, 1: 0.36}\n",
      "Iteration:  4\n",
      "Reward Function:  [ 0.00e+00  0.00e+00 -2.01e-03 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03  0.00e+00 -2.01e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-03\n",
      "  0.00e+00 -2.00e-03 -2.00e-03  0.00e+00  0.00e+00  0.00e+00  2.01e-03  1.88e-03  1.88e-03 -1.22e-04 -1.28e-04  1.94e-03  1.00e-01  1.21e-04  0.00e+00\n",
      "  0.00e+00  0.00e+00 -2.08e-03  5.00e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6075, 1: 0.3925}\n",
      "Iteration:  5\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.5775, 1: 0.4225}\n",
      "Iteration:  6\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.5475, 1: 0.4525}\n",
      "Iteration:  7\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Finished BM Search. Entropy: 0.6886278683856617. Max Ent possible: 0.6931471805599453. Cover: {0: 0.5475, 1: 0.4525}. Behaviors: {0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]}\n",
      "Behavior map:  ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Maximum Entropy Reward Update:  [ 0.  0. -0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0. -0. -0.  0.  0.  0. -0.  0.]\n",
      "Finished episode 2.\n",
      "Started episode 3.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n",
      "posterior_dist: [[-49.36 -49.51 -49.68 -49.88 -50.1  -50.35 -50.63 -50.93 -51.27 -51.63 -52.03   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-49.46 -49.65 -49.86 -50.11 -50.38 -50.68 -51.01 -51.37 -51.76 -52.18 -52.63   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-49.63 -49.87 -50.13 -50.42 -50.75 -51.11 -51.5  -51.92 -52.38 -52.88 -53.43   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-49.89 -50.18 -50.5  -50.86 -51.25 -51.68 -52.15 -52.68 -53.25 -53.88   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-50.26 -50.62 -51.02 -51.46 -51.96 -52.51 -53.13 -53.79 -54.5    -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-50.8  -51.27 -51.8  -52.39 -53.05 -53.76 -54.51   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-51.66 -52.3  -53.   -53.77   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-52.98 -53.8    -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.7206887495886872, 0.7310541157689847]\n",
      "Computed Region of Interest. Size = 0.06\n",
      "Region of interest:  [  0  20   1  40  21   2  22  41   3  60   4  23  42  61  80   5  24  43  62  81   6  25  44 100  63]\n",
      "Updated parameter mesh of shape:  (25, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.7  0.74]\n",
      " [0.7  0.75]\n",
      " [0.7  0.77]\n",
      " [0.7  0.78]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.71 0.73]\n",
      " [0.71 0.74]\n",
      " [0.71 0.75]\n",
      " [0.71 0.77]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.73 0.73]\n",
      " [0.73 0.74]\n",
      " [0.73 0.75]\n",
      " [0.74 0.7 ]\n",
      " [0.74 0.71]\n",
      " [0.74 0.73]\n",
      " [0.74 0.74]\n",
      " [0.75 0.7 ]\n",
      " [0.75 0.71]\n",
      " [0.77 0.7 ]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'RRDDDDRDRDR': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 2, 3, 10, 17, 24, 31, 32, 39, 40, 47, 48]})\n",
      "Cover:  {0: 0.8225, 1: 0.1775}\n",
      "Iteration:  1\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.9575, 1: 0.0425}\n",
      "Iteration:  2\n",
      "Reward Function:  [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.\n",
      " -0.  -0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1 -0.   0.   0.   0.  -0.   0.5]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.9375, 1: 0.0625}\n",
      "Iteration:  3\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.    0.    0.    0.01  0.01  0.    0.    0.01  0.1  -0.    0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.8725, 1: 0.1275}\n",
      "Iteration:  4\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.    0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.8425, 1: 0.1575}\n",
      "Iteration:  5\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.    0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.8225, 1: 0.1775}\n",
      "Iteration:  6\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.    0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.795, 1: 0.205}\n",
      "Iteration:  7\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.    0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.735, 1: 0.265}\n",
      "Iteration:  8\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6875, 1: 0.3125}\n",
      "Iteration:  9\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6425, 1: 0.3575}\n",
      "Iteration:  10\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6075, 1: 0.3925}\n",
      "Iteration:  11\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.5525, 1: 0.4475}\n",
      "Iteration:  12\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Finished BM Search. Entropy: 0.6876245064056856. Max Ent possible: 0.6931471805599453. Cover: {0: 0.5525, 1: 0.4475}. Behaviors: {0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]}\n",
      "Behavior map:  ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Reward Function:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Maximum Entropy Reward Update:  [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01 -0.01 -0.01  0.    0.    0.   -0.    0.01]\n",
      "Finished episode 3.\n",
      "Started episode 4.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n",
      "posterior_dist: [[-66.53 -66.67 -66.85 -67.07 -67.32 -67.61 -67.94   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-66.64 -66.85 -67.09 -67.37 -67.69 -68.05   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-66.86 -67.13 -67.44 -67.8  -68.19   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-67.2  -67.55 -67.95 -68.38   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-67.71 -68.16   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-68.46   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.7161060751655578, 0.7219301644202163]\n",
      "Computed Region of Interest. Size = 0.04\n",
      "Region of interest:  [ 0 20  1 21  2 40  3 22 41 60  4 23 42 61  5 24]\n",
      "Updated parameter mesh of shape:  (16, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.7  0.74]\n",
      " [0.7  0.75]\n",
      " [0.7  0.77]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.71 0.73]\n",
      " [0.71 0.74]\n",
      " [0.71 0.75]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.73 0.73]\n",
      " [0.74 0.7 ]\n",
      " [0.74 0.71]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [ 0.    0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.09 -0.01  0.    0.    0.   -0.    0.51]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), p2idx={'DDDDDDL': 0}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42]})\n",
      "Cover:  {0: 1.0}\n",
      "Iteration:  1\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -1.79e-03  2.36e-04  1.28e-02  1.27e-02  1.16e-02  1.16e-02  1.31e-02  8.72e-02 -1.08e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.13e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.7925, 1: 0.2075}\n",
      "Iteration:  2\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -2.67e-03  2.36e-04  1.36e-02  1.36e-02  1.25e-02  1.25e-02  1.40e-02  8.63e-02 -1.08e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.14e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.7075, 1: 0.2925}\n",
      "Iteration:  3\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -3.56e-03  2.36e-04  1.45e-02  1.45e-02  1.33e-02  1.34e-02  1.49e-02  8.54e-02 -1.08e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.15e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.6275, 1: 0.3725}\n",
      "Iteration:  4\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -3.56e-03  2.36e-04  1.54e-02  1.54e-02  1.42e-02  1.42e-02  1.58e-02  8.46e-02 -1.16e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.16e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.5575, 1: 0.4425}\n",
      "Iteration:  5\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -3.56e-03  2.36e-04  1.63e-02  1.62e-02  1.51e-02  1.51e-02  1.67e-02  8.37e-02 -1.25e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.17e-01]\n",
      "Finished BM Search. Entropy: 0.6865200278550464. Max Ent possible: 0.6931471805599453. Cover: {0: 0.5575, 1: 0.4425}. Behaviors: {0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]}\n",
      "Behavior map:  ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Reward Function:  [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -3.56e-03  2.36e-04  1.54e-02  1.54e-02  1.42e-02  1.42e-02  1.58e-02  8.46e-02 -1.16e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.16e-01]\n",
      "Maximum Entropy Reward Update:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.02  0.02  0.01  0.01  0.02 -0.02 -0.01  0.    0.    0.   -0.    0.02]\n",
      "Finished episode 4.\n",
      "Started episode 5.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n",
      "posterior_dist: [[-80.56 -80.79 -81.05 -81.34 -81.66 -82.01   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-80.7  -80.98 -81.29 -81.62 -81.99   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-80.91 -81.24 -81.6    -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-81.22 -81.61   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.7129400300647787, 0.7172511888897481]\n",
      "Computed Region of Interest. Size = 0.03\n",
      "Region of interest:  [ 0 20  1 40 21  2 60 41 22  3 42]\n",
      "Updated parameter mesh of shape:  (11, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.7  0.74]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.71 0.73]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.73 0.73]\n",
      " [0.74 0.7 ]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [ 0.00e+00 -8.80e-04 -1.12e-03 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.37e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  2.36e-04  0.00e+00 -1.12e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.36e-04  0.00e+00 -1.11e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.35e-04\n",
      "  0.00e+00 -1.11e-03 -1.11e-03  0.00e+00  0.00e+00 -3.56e-03  2.36e-04  1.54e-02  1.54e-02  1.42e-02  1.42e-02  1.58e-02  8.46e-02 -1.16e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00 -1.17e-03  5.16e-01]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), p2idx={'DDDDDDL': 0}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42]})\n",
      "Cover:  {0: 1.0}\n",
      "Iteration:  1\n",
      "Reward Function:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.01  0.01  0.02  0.08 -0.01  0.    0.    0.   -0.    0.52]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDLD': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 35, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.605, 1: 0.395}\n",
      "Iteration:  2\n",
      "Reward Function:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.02  0.02  0.02  0.08 -0.01  0.    0.    0.   -0.    0.52]\n",
      "Behavior Map: ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Cover:  {0: 0.555, 1: 0.445}\n",
      "Iteration:  3\n",
      "Reward Function:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.02  0.02  0.02  0.08 -0.01  0.    0.    0.   -0.    0.52]\n",
      "Finished BM Search. Entropy: 0.6870849202888889. Max Ent possible: 0.6931471805599453. Cover: {0: 0.555, 1: 0.445}. Behaviors: {0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]}\n",
      "Behavior map:  ExperimentResult(data=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), p2idx={'DDDDDDL': 0, 'DDDDDRRRRRD': 1}, pidx2states={0: [1, 8, 15, 22, 29, 36, 43, 42], 1: [1, 8, 15, 22, 29, 36, 37, 38, 39, 40, 41, 48]})\n",
      "Reward Function:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.02  0.02  0.02  0.08 -0.01  0.    0.    0.   -0.    0.52]\n",
      "Maximum Entropy Reward Update:  [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.02  0.02  0.02 -0.02 -0.01  0.    0.    0.   -0.    0.02]\n",
      "Finished episode 5.\n",
      "Started episode 6.\n",
      "Beginning calculation of log-likelihood. Calculating 400 samples.\n",
      "posterior_dist: [[-95.37 -95.6  -95.84 -96.11   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-95.37 -95.63 -95.9    -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-95.42 -95.71 -96.03   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [-95.57   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]\n",
      " [  -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf   -inf]]\n",
      "posterior_dist.shape: (20, 20)\n",
      "Mean Parameters: [0.714632641859153, 0.7114146854762339]\n",
      "Computed Region of Interest. Size = 0.02\n",
      "Region of interest:  [ 0 20 40 60  1 21 41  2]\n",
      "Updated parameter mesh of shape:  (8, 2)\n",
      "self._unnamed_parameter_mesh_ROI:  [[0.7  0.7 ]\n",
      " [0.7  0.71]\n",
      " [0.7  0.73]\n",
      " [0.71 0.7 ]\n",
      " [0.71 0.71]\n",
      " [0.73 0.7 ]\n",
      " [0.73 0.71]\n",
      " [0.74 0.7 ]]\n",
      "After stretching\n",
      "Initialized Reward Function R: [ 0.   -0.   -0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.    0.    0.    0.   -0.    0.   -0.    0.\n",
      "  0.    0.    0.   -0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.02  0.02  0.02  0.02  0.02  0.08 -0.01  0.    0.    0.   -0.    0.52]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m candidate_environments_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iterations_gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m candidate_environments_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstepsize_gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00025\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43menv_design\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_n_episodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcandidate_environments_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_environments_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/classes/CS282R/irl-environment-design/src/utils/environment_design.py:316\u001b[0m, in \u001b[0;36mEnvironmentDesign.run_n_episodes\u001b[0;34m(self, n_episodes, candidate_environments_args, bayesian_regret_how, verbose)\u001b[0m\n\u001b[1;32m    302\u001b[0m entropy_bm \u001b[38;5;241m=\u001b[39m EntropyBM(estimate_R \u001b[38;5;241m=\u001b[39m estimate_R,\n\u001b[1;32m    303\u001b[0m                        estimate_T \u001b[38;5;241m=\u001b[39m estimate_T,\n\u001b[1;32m    304\u001b[0m                        estimate_gamma \u001b[38;5;241m=\u001b[39m estimate_gamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m                        verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m    311\u001b[0m                        )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m#Find a reward function that maximizes the entropy of the Behavior Map. \u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m#TODO: also use transition function. Currently only do gradient updates on R. Do we want this?\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m updated_reward \u001b[38;5;241m=\u001b[39m \u001b[43mentropy_bm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBM_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_environment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_environment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mnamed_parameter_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_named_parameter_mesh_ROI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m#   shaped_parameter_mesh=self.shaped_parameter_mesh,\u001b[39;49;00m\n\u001b[1;32m    319\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mn_compute_BM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcandidate_environments_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_compute_BM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mn_iterations_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_environments_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_iterations_gradient\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mstepsize_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_environments_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstepsize_gradient\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m#Generate an environment in which we observe the human with maximal information gain.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m optimal_environment \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_environment)\n",
      "File \u001b[0;32m~/Desktop/Uni/classes/CS282R/irl-environment-design/src/utils/make_candidate_environments.py:198\u001b[0m, in \u001b[0;36mEntropyBM.BM_search\u001b[0;34m(self, base_environment, named_parameter_mesh, n_compute_BM, n_iterations_gradient, stepsize_gradient)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# for _ in range(n_compute_BM):\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entropy_maximized:\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Compute Behavior Map\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     bm_out \u001b[38;5;241m=\u001b[39m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_behavior_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mreward_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR_entropy_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mparameter_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamed_parameter_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m#    region_of_interest = region_of_interest\u001b[39;49;00m\n\u001b[1;32m    202\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavior Map:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bm_out)\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#Compute entropy of BM\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/classes/CS282R/irl-environment-design/src/utils/behavior_map.py:56\u001b[0m, in \u001b[0;36mcalculate_behavior_map\u001b[0;34m(environment, reward_update, parameter_mesh)\u001b[0m\n\u001b[1;32m     47\u001b[0m idx_ROI \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_parameter, parameter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parameter_mesh):\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \n\u001b[1;32m     55\u001b[0m         \u001b[38;5;66;03m#Get the transition function, reward function, and gamma from the parameter.\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m         _transition_func \u001b[38;5;241m=\u001b[39m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransition_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m         _reward_func \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mreward_function(\u001b[38;5;241m*\u001b[39mparameter\u001b[38;5;241m.\u001b[39mR)\n\u001b[1;32m     58\u001b[0m         _gamma \u001b[38;5;241m=\u001b[39m parameter\u001b[38;5;241m.\u001b[39mgamma\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mcustom_transition_func\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_transition_func\u001b[39m(p):\n\u001b[0;32m---> 29\u001b[0m     _T \u001b[38;5;241m=\u001b[39m \u001b[43mtransition_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabsorbing_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgoal_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     _T \u001b[38;5;241m=\u001b[39m insert_walls_into_T(T\u001b[38;5;241m=\u001b[39m_T, wall_indices\u001b[38;5;241m=\u001b[39mwall_states)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _T\n",
      "File \u001b[0;32m~/Desktop/Uni/classes/CS282R/irl-environment-design/src/utils/make_environment.py:44\u001b[0m, in \u001b[0;36mtransition_matrix\u001b[0;34m(N, M, p, absorbing_states)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# for a, action in enumerate([\"N\", \"E\", \"S\", \"W\"]):\u001b[39;00m\n\u001b[1;32m     43\u001b[0m             T[s, a, neighbors[action]] \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m---> 44\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m other_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m {action}:\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;66;03m# for other_action in set([\"N\", \"E\", \"S\", \"W\"]) - {action}:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m                 T[s, a, neighbors[other_action]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m p) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Make the transition matrix absorbing\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# make_absorbing(absorbing_states, T)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "candidate_environments_args = {}\n",
    "candidate_environments_args[\"generate_how\"] = \"entropy_BM\"\n",
    "candidate_environments_args[\"n_compute_BM\"] = 100\n",
    "candidate_environments_args[\"n_iterations_gradient\"] = 1\n",
    "candidate_environments_args[\"stepsize_gradient\"] = 0.00025\n",
    "\n",
    "\n",
    "env_design.run_n_episodes(n_episodes = 25,\n",
    "                          candidate_environments_args=candidate_environments_args,\n",
    "                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7141b86185e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+4AAAGLCAYAAABZQsh+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACeGUlEQVR4nOzdd1wT5x8H8E8SIOwlU2TKcO+9Z7XWXVfd1g6r1rpq1da9R3HVuqo42l/dtu6FE1eto05AFERRxAmyIbnfH5FAZJiwjvF5v173Irl77u57R5In39xzzyMRBEEAERERERERERVJUrEDICIiIiIiIqLsMXEnIiIiIiIiKsKYuBMREREREREVYUzciYiIiIiIiIowJu5ERERERERERRgTdyIiIiIiIqIijIk7ERERERERURHGxJ2IiIiIiIioCGPiTkRERERERFSEMXEnIiIiIiIiKsKYuBMREREREREVYUzci5CNGzdCIpEgLCxM7FCydPnyZTRq1AgmJiaQSCS4fv262CGVCkX9daGt6dOnQyKR4MWLF2KHAqB4ndfiFKuY0l5jREQFzc3NDYMHDxY7DMojiUSC6dOnix1GvmrRogVatGihfh4WFgaJRIKNGzdqlDt8+DBq1KgBQ0NDSCQSvHnzBgCwZcsWVKhQAfr6+rC0tCy0uHND2/9fSfl+wMS9kNy8eRM9evSAq6srDA0N4eTkhLZt22LFihVih6aVlJQU9OzZE69evcKSJUuwZcsWuLq6Zlk2LclIm/T09ODk5ITBgwcjIiIi233cvn0b/fv3h5OTE+RyOcqWLYt+/frh9u3b2e7j33//zbdjFNP58+cxffp09YcmUVGR2/czEam8/x4yNDSEt7c3Ro4ciWfPnokdXoESo25L+4Ke3RQZGan1topq3Tx37lz89ddfYodRJL3/fstucnNzEztUnT179gzjx49HhQoVYGxsDBMTE9SuXRuzZ8/W+TX68uVL9OrVC0ZGRli5ciW2bNkCExMTBAYGYvDgwShfvjzWrVuHtWvXZrn+woULIZFIcO3aNY35giDAysoKEokEoaGhGssSExMhl8vRt29fnWKldHpiB1AanD9/Hi1btoSLiwu+/PJLODg44NGjR7h48SKWLVuGb7/9FgAwYMAA9OnTB3K5XOSIM7t//z4ePnyIdevW4YsvvtBqnZkzZ8Ld3R2JiYm4ePEiNm7ciICAANy6dQuGhoYaZXfv3o3PPvsM1tbWGDp0KNzd3REWFob169dj586d2Lp1K7p161YQh1YknD9/HjNmzMDgwYMz/bpZlF8XVDiKwmtAl/czEWWW8T0UEBCAVatW4eDBg7h16xaMjY3FDq9A5FS3FbRVq1bB1NQ003xd4sgp/qCgIEil4lz/mjt3Lnr06IGuXbuKsv+irFmzZtiyZYvGvC+++AL16tXDV199pZ6X9tpISEiAnl7RT4cuX76MDh06IDY2Fv3790ft2rUBAP/++y/mz5+PM2fO4OjRo1mu6+rqioSEBOjr62ts7+3bt5g1axbatGmjnn/q1CkolUosW7YMnp6e2cbTpEkTAEBAQABq1qypnn/79m28efMGenp6OHfuHNzd3TX2mZycrF6XdFf0X6klwJw5c2BhYYHLly9n+uCPiopSP5bJZJDJZIUcnXbS4tSlwvv4449Rp04dAKoPTRsbGyxYsAB79+5Fr1691OXu37+PAQMGwMPDA2fOnIGtra162XfffYemTZtiwIABuHHjBjw8PPLngEQQFxcHExMTndcryq8L0l1uXgdF4TWg7fuZiLL2/nuoTJky8PX1xd9//43PPvss19tVKpVITk4uVT+gxcfHf/DHjh49esDGxqbAYuCP6eLK7nXv4eGR6bvisGHD4OHhgf79+2faTnF437x58wbdunWDTCbDtWvXUKFCBY3lc+bMwbp167JdP62lT0bZfa/X9vt+nTp1YGhoiICAAPUFSAA4d+4cypQpgzp16iAgIEDjnAcEBABAnhP30viZl4ZN5QvB/fv3Ubly5SzfBHZ2durH79/HmnZPSnZTmoiICHz++eewt7eHXC5H5cqVsWHDBq3ju3btGj7++GOYm5vD1NQUrVu3xsWLF9XLBw8ejObNmwMAevbsCYlEonHvjLaaNm0KQHU+Mlq0aBHi4+Oxdu1ajaQdAGxsbLBmzRrExcVh4cKFOu8T+PDx7dy5ExKJBKdPn8607po1ayCRSHDr1i31PG3Od1pTvTt37qBv376wsrLK9oNq+vTp+P777wEA7u7u6v9v2usgq/ub07YfHByM/v37w8LCAra2tpgyZQoEQcCjR4/QpUsXmJubw8HBAT///HOm/ebmdXPjxg1IJBLs3btXPe/KlSuQSCSoVauWRtmPP/4Y9evXz7SNN2/eqK9eWFhYYMiQIYiPj89VbGnnISQk5IPb1JY2+3748CGGDx8OHx8fGBkZoUyZMujZs2eme9Bzeh3oEvv7rwFdj/vUqVPqSrZ8+fJYs2ZNnu/3yu79nBVdz5c2xxUQEIC6detqHJO20n542LZtW6Zlhw4dgkQiwYEDB7TeHlFutGrVCgDUzUkXL16MRo0aoUyZMjAyMkLt2rWxc+fOTOtJJBKMHDkSf/zxBypXrgy5XI7Dhw/nahs7duxApUqVYGRkhIYNG+LmzZsAVHWfp6cnDA0N0aJFiyz717h06RLat28PCwsLGBsbo3nz5jh37px6+YfqNgD4/fffUbt2bRgZGcHa2hp9+vTBo0ePNPbTokULVKlSBVeuXEGzZs1gbGyMyZMn63Cms7dixQpUrlwZxsbGsLKyQp06dfC///1Pq/jfv8c97XM6ICAAo0aNgq2tLSwtLfH1118jOTkZb968wcCBA2FlZQUrKytMmDABgiBoxKPN/08ikSAuLg6bNm1Sx5QxDm3rz5yOPSdRUVEYOnQo7O3tYWhoiOrVq2PTpk3q5SkpKbC2tsaQIUMyrRsTEwNDQ0OMHz9ePS8pKQnTpk2Dp6cn5HI5nJ2dMWHCBCQlJWU67uxe93nx/j3S+fH9Sttj0taaNWsQEREBX1/fTEk7ANjb2+Onn37Kdv3373Fv0aIFBg0aBACoW7eu+jXk5uaGadOmAQBsbW1zvH/cwMAAdevW1XjPA6rEvWHDhmjcuHGWyywtLVGlShUAqgsZ48aNg7OzM+RyOXx8fLB48eJM7wtd//d5+X5Q1PGKeyFwdXXFhQsXcOvWLfWLVRu2traZmvukpKRgzJgxMDAwAKC636VBgwbqF7WtrS0OHTqEoUOHIiYmBqNHj85xH7dv30bTpk1hbm6OCRMmQF9fH2vWrEGLFi1w+vRp1K9fH19//TWcnJwwd+5cjBo1CnXr1oW9vb3O5yGtsrOystKYv2/fPri5uakTgfc1a9YMbm5uufoirc3xffLJJzA1NcX27dvVP1Ck2bZtGypXrqz+v+l6vnv27AkvLy/MnTs30wdRmu7duyM4OBh//vknlixZor5C8P6PGFnp3bs3KlasiPnz5+PAgQOYPXs2rK2tsWbNGrRq1QoLFizAH3/8gfHjx6Nu3bpo1qxZro4jTZUqVWBpaYkzZ86gc+fOAICzZ89CKpXiv//+Q0xMDMzNzaFUKnH+/HmNZmlpevXqBXd3d8ybNw9Xr17Fb7/9Bjs7OyxYsCDXsX1om9rSdt+XL1/G+fPn0adPH5QrVw5hYWFYtWoVWrRogTt37mS6EpTT6yAvsWuz7rVr19C+fXs4OjpixowZUCgUmDlzplavr5xk937Oiq7n60PHdfPmTXz00UewtbXF9OnTkZqaimnTpmn9udSzZ0+cOXMGM2bMQO/evdXzBUHApEmT0KxZM3zyySdangmi3En70atMmTIAgGXLlqFz587o168fkpOTsXXrVvTs2RP79+/P9Ho8ceIEtm/fjpEjR8LGxkZ9v64u2zh79iz27t2LESNGAADmzZuHjh07YsKECfj1118xfPhwvH79GgsXLsTnn3+OEydOaOz/448/Ru3atTFt2jRIpVL4+fmhVatWOHv2LOrVq/fBum3OnDmYMmUKevXqhS+++ALPnz/HihUr0KxZM1y7dk3jYsfLly/x8ccfo0+fPujfv79W7/VXr15lmqenp6fe7rp16zBq1Cj06NED3333HRITE3Hjxg1cunQJffv2zXXd/O2338LBwQEzZszAxYsXsXbtWlhaWuL8+fNwcXHB3LlzcfDgQSxatAhVqlTBwIED1etq8//bsmVLpqbf5cuXB6B9HfahY89OQkICWrRogZCQEIwcORLu7u7YsWMHBg8ejDdv3uC7776Dvr4+unXrht27d2PNmjXq76sA8NdffyEpKQl9+vQBoLpy2rlzZwQEBOCrr75CxYoVcfPmTSxZsgTBwcGZ7uPP7nVfEHL7/UrXY9LG3r17YWRkhB49euTLsf3444/w8fHB2rVr1bfwlC9fHl27dsXmzZuxZ88e9a0m1apVy3Y7TZo0wdmzZxEWFqb+X5w7d079+pw2bRrevHkDS0tLCIKA8+fPo2HDhpBKpRAEAZ07d8bJkycxdOhQ1KhRA0eOHMH333+PiIgILFmyRGNf2v7v8/r9oMgTqMAdPXpUkMlkgkwmExo2bChMmDBBOHLkiJCcnKxRzs/PTwAghIaGZrut4cOHCzKZTDhx4oQgCIIwdOhQwdHRUXjx4oVGuT59+ggWFhZCfHx8jrF17dpVMDAwEO7fv6+e9+TJE8HMzExo1qyZet7JkycFAMKOHTs+eLxpx3H8+HHh+fPnwqNHj4SdO3cKtra2glwuFx49eqQu++bNGwGA0KVLlxy32blzZwGAEBMTo7GPy5cv58vxffbZZ4KdnZ2Qmpqqnvf06VNBKpUKM2fOVM/T9nxPmzZNACB89tlnOcaXZtGiRdn+77N6XaRt/6uvvlLPS01NFcqVKydIJBJh/vz56vmvX78WjIyMhEGDBul8HFn55JNPhHr16qmfd+/eXejevbsgk8mEQ4cOCYIgCFevXhUACH///XemmD///HON7XXr1k0oU6ZMrmLTdptZyeq8arvvrM7PhQsXBADC5s2bM8WX1etAl9jfj1WXdTt16iQYGxsLERER6nn37t0T9PT0BG2qAF3ez9nR9Xx96Li6du0qGBoaCg8fPlTPu3PnjiCTybQ6JkEQhMWLFwsymUzjc3jLli0CAOH8+fNabYNIG1m9h7Zu3SqUKVNGMDIyEh4/fiwIQub3SXJyslClShWhVatWGvMBCFKpVLh9+3amfemyDblcrvH5t2bNGgGA4ODgoK5rBUEQJk2apPH5o1QqBS8vL6Fdu3aCUqnU2Le7u7vQtm1b9bzs6rawsDBBJpMJc+bM0Zh/8+ZNQU9PT2N+8+bNBQDC6tWrMx1vVtI+R7KafHx81OW6dOkiVK5cOcdt5VQ3u7q6atSraf/n989Lw4YNBYlEIgwbNkw9L62+bt68ucY2tf3/mZiYaOw7jbZ1mDbHnpWlS5cKAITff/9dI8aGDRsKpqam6tfNkSNHBADCvn37NNbv0KGD4OHhoX6+ZcsWQSqVCmfPntUot3r1agGAcO7cOfW8nF73H5Ld+Urb7rRp09TP8/r9Spdj0paVlZVQvXp1rcs3b95c47UVGhoqABD8/PzU87L7Hp12/M+fP//gfg4cOCAAELZs2SIIgup7MwDh9OnTwtu3bwWZTCYcOHBAEARBuHXrlgBA/d7+66+/BADC7NmzNbbZo0cPQSKRCCEhIep5Of3v3///5cf3g6KMTeULQdu2bXHhwgV07twZ//33HxYuXIh27drByclJo8nxh2zevBm//vorFi5ciJYtW0IQBOzatQudOnWCIAh48eKFemrXrh2io6Nx9erVbLenUChw9OhRdO3aVeN+IEdHR/Tt2xcBAQGIiYnJ9XG3adMGtra2cHZ2Ro8ePWBiYoK9e/eiXLly6jJv374FAJiZmeW4rbTlusSjy/H17t0bUVFROHXqlLrczp07oVQq1VfkcnO+hw0bpnW8uZGxo0CZTIY6depAEAQMHTpUPd/S0hI+Pj548OBBro8jo6ZNm+Lq1auIi4sDoGqS1KFDB9SoUQNnz54FoLqSI5FIsrw94P1z0rRpU7x8+RIxMTG5ji2nbWpLl30bGRmp10tJScHLly/h6ekJS0tLreLLr9g/tK5CocDx48fRtWtXlC1bVl3O09MTH3/88Qe3n5E27+fs5PV8ZTwuhUKBI0eOoGvXrnBxcVGXqVixItq1a6f18Xh7e0OhUKibKScnJ2Pq1Kno2rUrGjZsqPV2iLSV8T3Up08fmJqaYs+ePXBycgKg+T55/fo1oqOj1Z+372vevDkqVaqUab4u22jdurXGVau0W5s+/fRTjTo5bX5aHXL9+nXcu3cPffv2xcuXL9Wfk3FxcWjdujXOnDkDpVKZ47nYvXs3lEolevXqpfFZ6+DgAC8vL5w8eVKjvFwuz7LpdU527dqFY8eOaUx+fn7q5ZaWlnj8+DEuX76s03Y/ZOjQoRq3IdWvXz9TvZxWX6ed0zS6/P/ep0sdlttjP3jwIBwcHDT6ZNDX18eoUaMQGxurvuWwVatWmW5Hev36NY4dO6bRymnHjh2oWLEiKlSooBFv2m0k778OsnvdF4TcfL8CdD8mbcTExHzwe7IYGjVqBKlUqr53/dy5c9DX10fdunXVV+vTmsun/U37Xnjw4EHIZDKMGjVKY5vjxo2DIAg4dOiQxnxt/vf59f2gKGNT+UJSt25d7N69G8nJyfjvv/+wZ88eLFmyBD169MD169c/+GK8fv06hg0bhs8++wxjx44FADx//hxv3rzB2rVrsx2uIWPnd+97/vw54uPj4ePjk2lZxYoVoVQq8ejRI1SuXFmHI023cuVKeHt7Izo6Ghs2bMCZM2cydeaS9kGUlsBnR9sEPyNdji/tPr1t27ahdevWAFTN5GvUqAFvb2/19nQ93xl70ywIGT+YAMDCwgKGhoaZOuSxsLDAy5cvAeT9ddO0aVOkpqbiwoULcHZ2RlRUFJo2bYrbt29rJO6VKlWCtbX1B2NOa2r9+vVrJCYm5iq2nLZpbm6e7bFkpMt5SUhIwLx58+Dn54eIiAiN5u/R0dGZ1svpdZCX2D+0blRUFBISErLsGTan3mKzos37OTu6nq+cjis+Ph4JCQnw8vLKtJ6Pjw8OHjyoVUxpxx8cHAxvb2+sWrUK4eHhvLedCkzae0hPTw/29vbw8fHR6JV8//79mD17Nq5fv65xL2xWfVFk95miyzayqj8AwNnZOcv5r1+/BgDcu3cPANT3yGYlOjo6x9to7t27B0EQsnwfA9Do/RoAnJycNJpca6NZs2Y5dk73ww8/4Pjx46hXrx48PT3x0UcfoW/fvmjcuLFO+3mfLuc17Zym0eX/9z5d6rDcHvvDhw/h5eWVqTf9ihUrqpcDqlsSPv30U/zvf/9DUlIS5HI5du/ejZSUFI3E/d69e7h79262tx8U9neqjHLz/QrQ/Zi0YW5u/sHvyWKwtLRE5cqVNZLzmjVrqn+AatSokcYyAwMD1KtXD4DqtVK2bNlM3+vffy2l0eZ///z583z5flCUMXEvZGmdOdStWxfe3t4YMmQIduzYoe4MIiuvX7/Gp59+Cm9vb/z222/q+Wm/aPfv3z/bCjSne1MKWr169dQ96Hbt2hVNmjRB3759ERQUpB6Gw8LCAo6Ojrhx40aO27px4wacnJy0TsJ0JZfL0bVrV+zZswe//vornj17hnPnzmHu3LnqMrk53xl/PS8IWfU0nl3v42nJUl5fN2mdnJ05cwYuLi6ws7ODt7c3mjZtil9//RVJSUk4e/ZstsP35RRfbmP70DFrQ5d9f/vtt/Dz88Po0aPRsGFDWFhYQCKRoE+fPlleacrpdZCX2PPjuLWlzfs5O7qer8I4Lg8PD0ilUty7dw9v377FnDlzMHjwYPWXBqL8lvE99L6zZ8+ic+fOaNasGX799Vc4OjpCX18ffn5+WXYYltVniq7byO59pm0dsmjRItSoUSPLsh/6TFAqlZBIJDh06FCW+3t//YKoSytWrIigoCDs378fhw8fxq5du/Drr79i6tSpmDFjRq63q8t5zfiZpuv/73261GEFdewZ9enTB2vWrMGhQ4fQtWtXbN++HRUqVED16tU1Yq5atSp8fX2z3Mb7P3YU9HeqjHLz/QrQ/Zi0UaFCBVy/fh3Jyck6/4BV0Jo0aYLVq1fjzZs3OHfuHBo1aqRe1qhRI2zYsAEpKSkICAhA7dq1c90TfGH+74syJu4iSqvAnz59mm0ZpVKJfv364c2bNzh+/LhGJ062trYwMzODQqHQGINRW7a2tjA2NkZQUFCmZYGBgZBKpbn6gMmKTCbDvHnz0LJlS/zyyy+YOHGielnHjh2xbt06BAQEZNm0Oq3ji6+//lqnfep6fL1798amTZvg7++Pu3fvQhAEjV+G83q+c5KX3r11ldfjSPvF9OzZs3BxcVF3Kti0aVMkJSXhjz/+wLNnz9QdtRRmbHmhy7537tyJQYMGafQmm9ZaoCixs7ODoaEhQkJCMi3Lap62cno/ZyU/z5etrS2MjIzUV/0yyuq9nh25XA4nJyfcu3cPixYtwtu3b7PtPZeooO3atQuGhoY4cuSIRkuWjE27C2Mb2kjrCM3c3PyDn5XZ1W3ly5eHIAhwd3dXt2oTg4mJCXr37o3evXsjOTkZ3bt3x5w5czBp0iQYGhoWat2sy/8vq7h0rT8/dOxZcXV1xY0bN6BUKjWuugcGBqqXp2nWrBkcHR2xbds2NGnSBCdOnMCPP/6osb3y5cvjv//+Q+vWrQv1XBekgjimTp064cKFC9i1a1eeho4sCE2aNMGqVatw/PhxXLt2TT0SA6BK3BMSEnDgwAE8ePAAn376qXqZq6srjh8/jrdv32pcdc/qtaSt/Pp+UJTxHvdCcPLkySyvFKU12ciqKXeaGTNm4MiRI/jzzz8zNRORyWT49NNPsWvXLo3hytI8f/48x7hkMhk++ugj/P333xrDszx79gz/+9//0KRJk3y9wt2iRQvUq1cPS5cuRWJionr+999/DyMjI3z99dcazY0AVa+ww4YNg7GxscaHgTZ0Pb42bdrA2toa27Ztw7Zt21CvXj2Nc57X852TtHG9CyPxy4/jaNq0KS5duoSTJ0+qE3cbGxtUrFhR3fN3dqMEFHRsuaXLvmUyWab39IoVK6BQKAosvtyQyWRo06YN/vrrLzx58kQ9PyQkJNP9Y7rK7v2cXRz5db5kMhnatWuHv/76C+Hh4er5d+/exZEjR3TalqenJ86fPw9fX198++23Wt2vT1QQZDIZJBKJxnsiLCxMpx6o82Mb2qhduzbKly+PxYsXIzY2NtPyjJ+V2dVt3bt3h0wmw4wZMzJ9NgiCkOm7QEF4fx8GBgaoVKkSBEFASkoKgMKvm7X9/5mYmGSKSZc6TJtjz0qHDh0QGRmpce96amoqVqxYAVNTU42ReaRSKXr06IF9+/Zhy5YtSE1N1bgYAqhGEImIiMhyDPKEhAR1XzrFSUEc07Bhw+Do6Ihx48YhODg40/KoqCjMnj07V/HmVdoFN19fX6SkpGhccXdzc4Ojo6N6OOeMF+c6dOgAhUKBX375RWN7S5YsgUQi0bkfHiB/vx8UVbziXgi+/fZbxMfHo1u3bqhQoQKSk5Nx/vx5bNu2DW5ubtl2uHLz5k3MmjULzZo1Q1RUFH7//XeN5f3798f8+fNx8uRJ1K9fH19++SUqVaqEV69e4erVqzh+/HiWw6FkNHv2bBw7dgxNmjTB8OHDoaenhzVr1iApKSnX46bn5Pvvv0fPnj2xceNGdQdUXl5e2LRpE/r164eqVati6NChcHd3R1hYGNavX48XL17gzz//VP/Krwtdjk9fXx/du3fH1q1bERcXh8WLF2faXl7Pd3Zq164NQDVER58+faCvr49OnTqpvzTkt7weR9OmTTFnzhw8evRII0Fv1qwZ1qxZAzc3t1wnQQV1jvNz3x07dsSWLVtgYWGBSpUq4cKFCzh+/Lh6WKeiZPr06Th69CgaN26Mb775Rl1RVqlSBdevX8/TtrN6P2clv8/XjBkzcPjwYTRt2hTDhw9Xf3GsXLnyB2+7ycjT0xPr1q2DpaUlJk2alKtYiPLDJ598Al9fX7Rv3x59+/ZFVFQUVq5cCU9PT61f0/mxDW1IpVL89ttv+Pjjj1G5cmUMGTIETk5OiIiIwMmTJ2Fubo59+/YByL5uK1++PGbPno1JkyYhLCwMXbt2hZmZGUJDQ7Fnzx589dVXGmN958bOnTuzbLLftm1b2Nvb46OPPoKDgwMaN24Me3t73L17F7/88gs++eQT9RXAwqybdfn/1a5dG8ePH4evry/Kli0Ld3d31K9fX+s6TJtjz8pXX32FNWvWYPDgwbhy5Qrc3Nywc+dOnDt3DkuXLs20bu/evbFixQpMmzYNVatWzXQr0oABA7B9+3YMGzYMJ0+eROPGjaFQKBAYGIjt27fjyJEj2d5eUlTpckzTp0/HjBkzcPLkSbRo0SLbbVpZWWHPnj3qjoD79++vfm1evXoVf/75p2idqrq4uMDZ2RkXLlyAm5ubRke4gOqq+65duyCRSDT6UOjUqRNatmyJH3/8EWFhYahevTqOHj2Kv//+G6NHj87Vd34g/74fFFkF2mc9CYIgCIcOHRI+//xzoUKFCoKpqalgYGAgeHp6Ct9++63w7Nkzdbn3h3xKG4ItuynNs2fPhBEjRgjOzs6Cvr6+4ODgILRu3VpYu3atVvFdvXpVaNeunWBqaioYGxsLLVu2zDQcUm6Gg8tqqDaFQiGUL19eKF++vMbQa4IgCDdu3BA+++wzwdHRUX0cn332mXDz5k2d9pGb40tz7NgxAYAgkUiyHeZKm/Oty3AaaWbNmiU4OTkJUqlU43WQ03Bw729/0KBBgomJSaZtN2/ePNPQL3l53cTExAgymUwwMzPT+D/+/vvvAgBhwIABmdbJLuasjk/b2HTZ5vuyK6PNvl+/fi0MGTJEsLGxEUxNTYV27doJgYGBmYYHyul1oEvs2Q0Hp+1x+/v7CzVr1hQMDAyE8uXLC7/99pswbtw4wdDQMNvz8/42dX0/Z5TX85XVcZ0+fVqoXbu2YGBgIHh4eAirV69Wr6+t+fPnCwA0hvchym/a1lfr168XvLy8BLlcLlSoUEHw8/PL8jUNQBgxYkS+byNtyKhFixZpzM+u/r927ZrQvXt3oUyZMoJcLhdcXV2FXr16Cf7+/hrlsqvbBEEQdu3aJTRp0kQwMTERTExMhAoVKggjRowQgoKC1GWyqr9yktNwcACEkydPCoKgGv6uWbNm6vjLly8vfP/990J0dLRW8Wc3HJy2w2tlVV9r+/8LDAwUmjVrJhgZGQkANOLQpg7T9tiz8uzZM/XnuYGBgVC1alWNYcYyUiqVgrOzc5bDfqVJTk4WFixYIFSuXFmQy+WClZWVULt2bWHGjBka8eT0uv+Q3AwHl5fvV9oe07hx4wSJRCLcvXtXq+N48uSJMGbMGMHb21swNDQUjI2Nhdq1awtz5szR2G5hDQeX5rPPPhMACH379s20zNfXVwAgVKxYMdOyt2/fCmPGjBHKli0r6OvrC15eXsKiRYs0hlMUhJz/9+///wQhf74fFFUSQSiAXoyIiKhI69q1K27fvp3lvWClxZIlSzB27Fi8evUqxx6wiYiI8lu9evXg6uqKHTt2iB0KFRO8x52IqIRLSEjQeH7v3j0cPHgwx6Z5pcGtW7dQrlw5Ju1ERFSoYmJi8N9//2HmzJlih0LFCK+4ExGVcI6Ojhg8eDA8PDzw8OFDrFq1CklJSbh27Vq24yiXBvXq1YONjU2JGNuViIiISjZ2TkdEVMK1b98ef/75JyIjIyGXy9GwYUPMnTu3VCftgiDgzp07GD58uNihEBEREX2QqE3lz5w5g06dOqFs2bKQSCRaDVly6tQp1KpVC3K5HJ6enti4cWOBx0lEVJz5+fkhLCwMiYmJiI6OxuHDh1GrVi2xwxKVRCJBbGxsgYyeQZpY1xMREeWdqIl7XFwcqlevjpUrV2pVPjQ0FJ988glatmyJ69evY/To0fjiiy9KzNh8REREJQ3reiIiorwrMve4SyQS7NmzB127ds22zA8//IADBw7g1q1b6nl9+vTBmzdvcPjw4UKIkoiIiHKLdT0REVHuFKt73C9cuIA2bdpozGvXrh1Gjx6d7TpJSUlISkpSP1cqlXj16hXKlCkDiURSUKESERFpTRAEvH37FmXLloVUWroHfMlNXQ+wvicioqItr3V9sUrcIyMjYW9vrzHP3t4eMTExSEhIgJGRUaZ15s2bhxkzZhRWiERERLn26NEjlCtXTuwwRJWbuh5gfU9ERMVDbuv6YpW458akSZMwduxY9fPo6Gi4uLjg0aNHMDc3FzEyIiIilZiYGDg7O8PMzEzsUIot1vdERFSU5bWuL1aJu4ODA549e6Yx79mzZzA3N8/2F3i5XA65XJ5pvrm5OStyIiIqUtikO3d1PcD6noiIiofc1vXF6ka6hg0bwt/fX2PesWPH0LBhQ5EiIiIiovzEup6IiCgzURP32NhYXL9+HdevXwegGgLm+vXrCA8PB6Bq9jZw4EB1+WHDhuHBgweYMGECAgMD8euvv2L79u0YM2aMGOETERHRB7CuJyIiyjtRE/d///0XNWvWRM2aNQEAY8eORc2aNTF16lQAwNOnT9UVOwC4u7vjwIEDOHbsGKpXr46ff/4Zv/32G9q1aydK/ERERJQz1vVERER5V2TGcS8sMTExsLCwQHR0NO95I6ISQ6FQICUlRewwKBsymQx6enrZ3tfGuin/8ZwSEVFRktd6qVh1TkdERJnFxsbi8ePHKGW/wxY7xsbGcHR0hIGBgdihEBERUTHDxJ2IqBhTKBR4/PgxjI2NYWtry17JiyBBEJCcnIznz58jNDQUXl5ekEqLVd+wREREJDIm7kRExVhKSgoEQYCtrW2OQ2WRuIyMjKCvr4+HDx8iOTkZhoaGYodERERExQh/8iciKgF4pb3o41V2IiIiyi1+iyAiIiIiIiIqwpi4ExERERERERVhTNyJiIgAhIWFQSKR4Pr162KHQkRERKSBiTsRUSm25Fgwlvvfy3LZcv97WHIsuED2O3jwYEgkEkgkEujr68Pd3R0TJkxAYmJiprL79+9H8+bNYWZmBmNjY9StWxcbN27UKKNN0h0aGoq+ffuibNmyMDQ0RLly5dClSxcEBgYCAJydnfH06VNUqVIlPw+ViIiIKM/YqzwRUSkmk0rg+y45H9XaSz1/uf89+B4Lxti23gW27/bt28PPzw8pKSm4cuUKBg0aBIlEggULFqjLrFixAqNHj8YPP/yAVatWwcDAAH///TeGDRuGW7duYfHixVrtKyUlBW3btoWPjw92794NR0dHPH78GIcOHcKbN28AADKZDA4ODgVxqEREVIgEAUhNBZKTVVNKiup5aqrm44xTTvMlEkBPL/eTQgEkJeV+Sk0FlErNSaHQfh4Ba9YAlpZiR5E3TNyJiEoQQRCQkKJ9Lf1FU3ekKJTwPRaMFIUS37Qoj1Wn7mPFiRB828oTXzR1R3xyqlbbMtKX6dS7vVwuVyfKzs7OaNOmDY4dO6ZO3B89eoRx48Zh9OjRmDt3rnq9cePGwcDAAKNGjULPnj1Rv379D+7r9u3buH//Pvz9/eHq6goAcHV1RePGjdVlwsLC4O7ujmvXrqFGjRoYPHgwNm3alGlbJ0+eRIsWLZCUlIQff/wRf/75J968eYMqVapgwYIFaNGihdbngIiIVOLigIgI1fTkiebft2/Tk/CcppSU9MdEGS1bJnYEecfEnYioBElIUaDS1CO5WnfFiRCsOBGS7fMPuTOzHYwNclet3Lp1C+fPn1cn1QCwc+dOpKSkYPz48ZnKf/3115g8eTL+/PNPrRJ3W1tbSKVS7Ny5E6NHj4ZMJvvgOsuWLcP8+fPVz+fPn48///wTFSpUAACMHDkSd+7cwdatW1G2bFns2bMH7du3x82bN+Hl5ZXdZomISg1BUCXRz59rJuJZJecxMQUbS3ZXw/X1P3zFHMj6arw2U0oKIJMBcnnuJ3191Tak0uynnJZzxFjAzEzsCPKOiTsREYli//79MDU1RWpqKpKSkiCVSvHLL7+olwcHB8PCwgKOjo6Z1jUwMICHhweCg7W7B9/JyQnLly/HhAkTMGPGDNSpUwctW7ZEv3794OHhkeU6FhYWsLCwAADs3r0ba9aswfHjx+Hg4IDw8HD4+fkhPDwcZcuWBQCMHz8ehw8fhp+fn0YLASKiokyhABISgPj49L9pU9rzuDjVFBur3d+Mj1O1a7QFADA1BZycgLJlNf9aWKgSWAMD3ae0xJzJKxV3TNyJiEoQI30Z7sxsp/N6ac3j9WUSpCgEfNvKE9+0KK/zvnXRsmVLrFq1CnFxcViyZAn09PTw6aef6rQNXYwYMQIDBw7EqVOncPHiRezYsQNz587F3r170bZt22zXu3btGgYMGIBffvlF3bT+5s2bUCgU8PbW7AMgKSkJZcqUKbBjICLKiUIBPHoE3L+vmkJCgAcPgFevsk/Mk5IKPi49PcDRMeukPO2vk1PJuCpKVFCYuBMRlSASiUTn5urL/e9hxYkQjG3rjVGtvdQd0+nLpBod1uU3ExMTeHp6AgA2bNiA6tWrY/369Rg6dCgAwNvbG9HR0Xjy5In6qnaa5ORk3L9/Hy1bttRpn2ZmZujUqRM6deqE2bNno127dpg9e3a2iXtkZCQ6d+6ML774Qh0XAMTGxkImk+HKlSuZmt2bmprqFBMRkS4SEoDQ0PTkPC1Bv38fCAtTNc3OLUNDwNhYNRkZpf81MVFdDc/NXxMTwNxc1WSbiHKPiTsRUSmWsff4tCQ97W9Wvc0XFKlUismTJ2Ps2LHo27cvjIyM8Omnn+KHH37Azz//jJ9//lmj/OrVqxEXF4fPPvss1/uUSCSoUKECzp8/n+XyxMREdOnSBRUqVICvr6/Gspo1a0KhUCAqKgpNmzbNdQxERICq9++YGNWV8ZcvM/8ND09P0CMict6WgQHg7g6UL58+2dmlJ+QZk/KMk6Ehk2uiooyJOxFRKaZQChpJe5q05wqlUGix9OzZE99//z1WrlyJ8ePHw8XFBQsXLsS4ceNgaGiIAQMGQF9fH3///TcmT56McePGadUxHQBcv34d06ZNw4ABA1CpUiUYGBjg9OnT2LBhA3744Ycs1/n666/x6NEj+Pv74/nz5+r51tbW8Pb2Rr9+/TBw4ED8/PPPqFmzJp4/fw5/f39Uq1YNn3zySb6cEyIqngQBiIoCHj5UJd1RUdkn5a9eAa9f6zZsl7m5ZmKecSpXTtVRGRGVLEzciYhKsTE5jNNeGFfaM9LT08PIkSOxcOFCfPPNNzAxMcHo0aPh4eGBxYsXY9myZVAoFKhcuTJWrVqFIUOGaL3tcuXKwc3NDTNmzEBYWBgkEon6+ZgxY7Jc5/Tp03j69CkqVaqkMT9tODg/Pz/Mnj0b48aNQ0REBGxsbNCgQQN07NgxT+eBiIq+lBTg8eP0xPzhw/QpPFw1JSbqvl0TE8DaGihTRvOvk5Nmcl6mDDtbIyptJIIgFN7llCIgJiYGFhYWiI6Ohrm5udjhEBHlSWJiIkJDQ+Hu7g5DQ0Oxw6Ec5PS/Yt2U/3hOKa+io4Hbt1XTgweaifmTJ6rm7TmRSFQdr7m4qDpmyyohz/jXykrVXJ2ISqa81ku84k5EREREpVZcHHDnDnDrlipJT/v7+HHO68nlqqTcxQVwdU2f0p6XK6e635yIKD8wcSciIiKiEi8xEQgMzJygh4Zmv46TE1ClCuDllTkxt7NjZ25EVHiYuBMRERFRifLqFXDlCvDvv6q/N2+qemTPrnm7nZ0qQa9cOf1v5cqApWWhhk1ElC0m7kRERERUbL15A1y9qkrS0xL1Bw+yLmtllXWCbmtbqCETEemMiTsRUQlQyvoZLZb4Pyre4uKyXyaTaXYqllNZqVQ1hnZuysbHq4YZy4pEohqLO6uyiYlAcrLqfmsDA1W8GcsmJOTc0ZqJSe7KJibmPMSZLmWNjVXHGBMDXLyoStCvXVMl7Nkl6eXLAzVrAjVqAFWrqhJ0e3vN3tiNjNKbuycnq3qLz44uZQ0N04dk06VsSoqqfHbkckBPT/eyqalAUlL2ZQ0MAH193csqFDn3nq+vn36fvy5llUrVay0/yurpqc4FoHpPxMfnT1ld3vdF/TPiQ2WL02cEoHr9pqbmT9mM73vRCaVMdHS0AECIjo4WOxQiojxLTk4W7ty5I7x580bsUOgDXrx4Idy5c0dITU3NtIx1U/7L73Oq+oqb9dShg2ZZY+PsyzZvrlnWxib7snXqaJZ1dc2+bKVKmmUrVMg5ZhMTQbCyEgR7e0EwMMi+nIGBIHTvLghDhwrCTz8JgpdX9mWNjTVj6NAh5xgy6tEj57K9ewuCj0/OZdKmnTsF4dUr1XaHD8+5bGhoegzjx+dc9tat9LLTpuVc9p9/0ssuXJhz2ZMn08v+8kvOZffvTy/r55dz2e3b08tu355zWT+/9LL79+dc9pdf0suePJlz2YUL08v+80/OZadNSy9761bOZcePTy8bGppz2eHD08tGReVcdtCg9LKxsTmX7dFD4yWcY9mi+BlRqVL2ZV1dNcvWqZN9WRsbzbLNm2dftiA/I2Jj08sOGpRz2aio9LK6fEbkVV7rJV5xJyIqxvT09GBsbIznz59DX18f0iLzszClEQQB8fHxiIqKgqWlJWRpl9aI8llSEnD4MLB1KxAUlHPZuLicr+SlSU4Gdu/Wbv+JiUD//qqhzxwdVUOm5eSLL4Dnz4GoKNU96DnZti39sYlJzrE3a6ZqEk9EVJJwHHciomIuOTkZoaGhUH5oUGESlaWlJRwcHCDJ2E73HdZN+S+/z2lRbQabkgKcPg3s3Ans26caezyNmxvQsyfw6aeqXtGTktKbbctkqsdJSarm52nN6dOmtLJpTbFfvAAiI1VDpD19qnocGZlzE/Dc0tdX3XOeNtnYABUrAvXqAbVrA+bmBdMMlk3ldS/LpvLpz4vqZ0QaNpXPXdn8bCqf13qJiTsRUQmgVCqRnNM3OBKVvr5+jlfaWTflv5J8ThUKICBAdWV9505VUp3GyQno3Rvo0weoU0fzfu78JgjA69fpifzTp5mntPlyuarn9g9NtraqxLwg4yYiEkNe6yU2lSciKgGkUikMM/6cT0QliiAA//yjSta3b9dshm5rq7qy3qcP0Lhx4XWkJJEA1taqqXLlwtknEVFpxcSdiIiIqAhKSQEuXAAOHFAl62Fh6cssLYHu3VXJesuW6U2iiYioZOLHPBEREVERERGh6mDu0CHg2DHV/edpTEyALl1UyfpHH6Xfi0tERCUfE3ciIiIikaSkAOfPqxL1Q4eAGzc0l5cpA7Rrp0rYO3bU7DCKiIhKDybuRERERIXo8eP0RP34ceDt2/RlEomq9/SPP1ZNtWun9zhORESlFxN3IiIiogKUnAycO5eerN+6pbnc1lZ1Vf3jj1VN4G1sxImTiIiKLibuRERERPksIQE4ciR9fPWM96pLpUD9+ulX1WvVKrye4ImIqHhi4k5ERESUD+LjVVfUd+4E9u8HYmPTl9nZAe3bp19Vt7YWL04iIip+mLgTERER5VJsLHDwoCpZP3BAlbyncXEBevQAenRNRP068ZDKpIBECkACpEoBvHsuyfhYItKREBFRUcbEnYiIiEgHMTGqJH3HDtUV9sTE9GXu7gJ6do1Bj+YXUMdxHyQvzgGPbwKPlDrsQfJeQi8DbJsAVX4E7Jrl9+EQEVExwMSdiIiI6APevFHdq75zp+re9aSk9GWeHono2eYmetTbhZpWv0OSGAHEAQjJ7d4EQFCopjSRR1WTXXOgyhTAvhWvzhMRlSJM3ImIiIiycf48MHcucPSoasz1ND5uz9Gz8WH0qLYS1ZwupefQiQAkeoBVTcC2sWqyaQQY2gNQAoISqsQ87bEy/fH7z9Mep0QDwb8CD9YDUaeBE6cBm4aqBN6xPRN4IqJSgIk7ERERUTbiXr3GgQNWAIBKLiHoWecP9Ki3A5XL3U7Pl/UtVYl0WqJeph6gZ5zF1vIwIHu9Vaqm8ncWAiFrgRcXgFMdAOs6qgTeqRMTeCKiEoyJOxEREVE2Wvgcxdxe19Gl9t+oVO6uaqapB2AzID1Rt6j07n70AmZcDqizHKg8Cbi7GLi3Gnj1L3CmC2BZHajyE+DcvXBiISKiQiURBEEQO4jCFBMTAwsLC0RHR8Pc3FzscIiIiFg3FYB8O6fxj4GznwI2jdMTdSOH/As0LxKfA4G+QPAvQOq7secsKgOVfwRcegHSPFzhJyKifJXXeomJOxERkchYN+W/UnVOk14BQUuBoOWq++EBwMwbqDwZcOsHSNnAkohIbHmtl9iWioiIiKg4k1sD1WYCXcKAarMAA2vgbTBwcTCwzxsI+Q1QJIsdJRER5QETdyIiIqKSwMBSdZ97lzCgxnxAbgvEhQL/fAns9QDuLAKSo8WOkoiIcoGJOxEREVFJom8GVPoB6BIK1PIFDB2AhAjg+gTgL2fg2veqe/eJiKjYYOJOREREVBLpmQAVxqiuwNdfD5hXBFLfqnqk/9sdOD8QeH1D7CiJiEgLTNyJiIiISjKZHCj/OfDJLaD5fsCuOSCkAmFbgEPVgRPtgMjjQOnqr5iIqFhhN6NEREREpYFECjh9oppeXgbu/gw82gFEHlVNVjWACuMB116AVD//9pvyVjVcnaBUTVCmP37/OZSAoMi8XGYMGFipJj0TQCLJv/iIxKJMBRSJgDJJ9Tdtev+5RAJI5YDMUHOSZnws5xCQJRwTdyIiIqLSpkxdoMlWIHYeELgEuL8eeH0duNAf+G8S4DMa8PwC0NdyyKLk10DMPSA2BHj7bkp7nPQ8f2OX6KUn8dpO+maAzATQM1b9CMAEh3SlTFH9CJUSoxp2MSUmiymb+Yq4rJNyQZG/MUr1MyfzMsN3Q0KW8h+7Wh4FDG3EjiJPRE/cV65ciUWLFiEyMhLVq1fHihUrUK9evWzLL126FKtWrUJ4eDhsbGzQo0cPzJs3D4aGhoUYNREREemC9X0RZeoO1FkOVJ0OhKxWjQUf/wi4Ng64NRPw/BrwGQUYlQWSXmgm5BkfJ7/KeT8SmeqKP6Sqv+8/zmkZJEBqnOrHASFVNSU9z9sPAlIDVQKvlyGZV//NYZ6eybsfADI8V8/L8FwqZ6uAwiYIgCIh68Q5NQ5QxKuWp777q4gHUhO0m58aq3pckKT6mlfV1Qm4XLVckQgokgBloubVeCE1fRvKFNWU+rZgYy2OMp6nYkrUxH3btm0YO3YsVq9ejfr162Pp0qVo164dgoKCYGdnl6n8//73P0ycOBEbNmxAo0aNEBwcjMGDB0MikcDX11eEIyAiIqIPYX1fDMitgcqTgQpjgdDfgcCfgZhA4O5CIGgJIDNSJUA5MSoLmHkCpp6qv2Ze756XV13xzitBSE/gtZ1S0v7GqhKxNMpk1ZTyJu9xZUUizZDwv0vkpXqq1gISvXdJWsbn7+ZlfK7+q69K3rL9USGHHx5kRuK0LlAqVMmj+opzoiqhTPvhRZmiaiae1fO0cspUQHg3XxGfzRXuGM395PcV7KzIjFQtUdSTxXvPs5iX9r+QZUjG86uZuzI1c9N6RWKGBD9B9f8o7QysxI4gzySCIF5PJPXr10fdunXxyy+/AACUSiWcnZ3x7bffYuLEiZnKjxw5Enfv3oW/v7963rhx43Dp0iUEBARotc+YmBhYWFggOjoa5uZaNv8iIiIqQCW9bmJ9XwwJSiDiABC4GIg6kz7f2DlDcv4uMTfzBEw9VAljUSYI7xKZ+HdXUePSH2v8jdOcpy4Xl/nx+8+VyWIfZWZSefatCfRMMiT9OSxTpgKpGZLl5GjN5+83F0+NE/GAJZpJs54ZoG/6LnE2BvSM0hNpPWPt5uuZvkvGzfK3/wcqVfJaL4l2xT05ORlXrlzBpEmT1POkUinatGmDCxcuZLlOo0aN8Pvvv+Off/5BvXr18ODBAxw8eBADBgzIdj9JSUlISkpSP4+J+cCvxURERJRvWN8XUxIpUK6TaooJUl3JNHFXJTHFlUTyLgkzAuRlCmYfaVeH1Yl9fHpCL2S8qpya+aqykGHe+1enFUk5/7iQ1V91TElAchKA1wVzzDmRyt/1L2CcoRWBvmZrgvdbF2RVTmb83hVtswyJ+XtXu9l5IZVQoiXuL168gEKhgL29vcZ8e3t7BAYGZrlO37598eLFCzRp0gSCICA1NRXDhg3D5MmTs93PvHnzMGPGjHyNnYiIiLTD+r4EMPcRO4LiQ6oHSM2179SvoAhKVeuC1HhVx2ipCe/+vpf8Z9X6INPjOFVCrWvzcH3z9PuziSjPRO+cThenTp3C3Llz8euvv6J+/foICQnBd999h1mzZmHKlClZrjNp0iSMHTtW/TwmJgbOzs6FFTIRERHpiPU9UR5JpO+auxsDKN49aRORimiJu42NDWQyGZ49e6Yx/9mzZ3BwcMhynSlTpmDAgAH44osvAABVq1ZFXFwcvvrqK/z444+QSqWZ1pHL5ZDL+WsfERGRGFjfExER5V3mmq+QGBgYoHbt2hodzyiVSvj7+6Nhw4ZZrhMfH5+pspbJVD0witjHHhEREWWD9T0REVHeidpUfuzYsRg0aBDq1KmDevXqYenSpYiLi8OQIUMAAAMHDoSTkxPmzZsHAOjUqRN8fX1Rs2ZNddO5KVOmoFOnTuoKnYiIiIoW1vdERER5I2ri3rt3bzx//hxTp05FZGQkatSogcOHD6s7sAkPD9f4xf2nn36CRCLBTz/9hIiICNja2qJTp06YM2eOWIdAREREH8D6noiIKG9EHcddDBzXlYiIihrWTfmP55SIiIqSvNZLot3jTkREREREREQfxsSdiIiIiIiIqAhj4k5ERERERERUhDFxJyIiIiIiIirCmLgTERERERERFWFM3ImIiIiIiIiKMCbuREREREREREWYntgBEBERERV5qXHZL5PIAJmhdmUhBfSMclk2HoCQXRCAnnEuyyYAUGYfhp5J7soqEgFBkT9lZcaARPKubBIgpOZTWSNA8u46liIZEFLyp6zUEJDKdC+rTAGUyTmUlQNSvVyUTQWUSTmUNQCk+rkoqwCUidmXlegDMgPdywpKQJGQT2X1AJn8XVkBUMTnU1kd3vf8jMi6bHH7jBAZE3ciIiKiD9lumv2ysh2AFgfSn++yy/4Lv11zoM2p9Od/uwFJL7Iua10HaH85/fmBSkDcw6zLWlQCPrmd/vxIXSD6TtZlTVyBLmHpz483A179m3VZuQ3w6fP056c+BqJOZ11WZgz0zpBknP0UeHIw67IA0DdD0nB+APBoZ/Zle8Wmf4n/52sgdFP2ZbtHAYa2qsdXxwL3fs2+bOdQwNRN9fjGj8DdxdmX7XALsKysenx7LnBrRvZl2/0DlKmrehy0DLg+IfuyrU8C9i1Uj0PWAv+OzL5s8/2A0yeqx2F/ABeHZF+2yXbApafq8eM9QECv7Ms28AM8BqsePz0CnO6Yfdk6vwDeI1SPn58F/FtmX7bGQqDS96rHr68CR+plX7bKNKDadNXj6LvAwSrZl604Hqi5SPU4LhzY6559Wa/hQN2VqsdJL4DddtmXdR8ENNyoeqyIz/l979wDaLoj/Tk/I1RK8meEyIrGzwdERERERERElCWJIAjZtZEokWJiYmBhYYHo6GiYm5uLHQ4RERHrpgKQ7+eUzWB1L1vcmsGyqXwuyrKpvBo/I3QvW9w+I/Ior/USm8oTERERfUjGL5CilTX+cJlclTX6cJnclM2YqORrWTkAeQGUNQBgIG5ZqX56UpyvZfXSk/h8LSsDpFq+hnUpK5Fq/97QqaykYMoCRaQsPyNUZQvoM0JkbCpPREREREREVIQxcSciIiIiIiIqwpi4ExERERERERVhTNyJiIiIiIiIijAm7kRERERERERFGBN3IiIiIiIioiKMiTsRERERERFREcbEnYiIiIiIiKgIY+JOREREREREVIQxcSciIiIiIiIqwpi4ExERERERERVhTNyJiIiIiIiIijAm7kRERERERERFGBN3IiIiIiIioiKMiTsRERERERFREcbEnYiIiIiIiKgIY+JOREREREREVIQxcSciIiIiIiIqwpi4ExERUZZCQkJw5MgRJCQkAAAEQRA5IiIiotKJiTsRERFpePnyJdq0aQNvb2906NABT58+BQAMHToU48aNEzk6IiKi0oeJu46WHAvGcv97WS5b7n8PS44FF3JERERE+WvMmDHQ09NDeHg4jI2N1fN79+6Nw4cPixgZERFR6cTEXUcyqQS+WSTvy/3vwfdYMGRSiUiRERER5Y+jR49iwYIFKFeunMZ8Ly8vPHz4UKSoiIiISi89sQMobka19gIA+L67sj6qtZc6aR/b1lu9nIiIqLiKi4vTuNKe5tWrV5DL5SJEREREVLoxcc+FjMn70uPBUApg0k5ERCVG06ZNsXnzZsyaNQsAIJFIoFQqsXDhQrRs2VLk6IiIiEofJu65NKq1lzppl0rApJ2IiEqMhQsXonXr1vj333+RnJyMCRMm4Pbt23j16hXOnTsndnhERESlDu9xz6Xl/vegfDcqjlIAlh5np3RERFQyVKlSBcHBwWjSpAm6dOmCuLg4dO/eHdeuXUP58uXFDo+IiKjU4RX3XEi7p/271l7YeD4M0QkpWHr8HqQSCa+8ExFRiWBhYYEff/xR7DCIiIgITNx19n5HdI9ex2P31QjUcrHU6LCOiIiouDpz5kyOy5s1a1ZIkRARERHAxF1nCqWg0RFd+8oO2H01As9ikjCmjRcUae3niYiIiqkWLVpkmieRpA93qlAoCjEaIiIiYuKuozFtvTWeN/O2hZG+DBFvEtCqgj2qlrMQKTIiIqL88fr1a43nKSkpuHbtGqZMmYI5c+aIFBUREVHpxcQ9jwz1ZWhZwRYHb0bi8O2nTNyJiKjYs7DIXJe1bdsWBgYGGDt2LK5cuSJCVERERKUXe5XPB+0qOwAAjtx+JnIkREREBcfe3h5BQUFih0FERFTq8Ip7PmhZwQ76MglComIREvUWnnZmYodERESUazdu3NB4LggCnj59ivnz56NGjRriBEVERFSKMXHPB+aG+mjsaYNTQc9x5PYzJu5ERFSs1ahRAxKJBIKg2eFqgwYNsGHDBpGiIiIiKr2YuOeTdpUd3iXukRjR0lPscIiIiHItNDRU47lUKoWtrS0MDQ1FioiIiKh0Y+KeT9pWssfkPTdx43E0It4kwMnSSOyQiIiIcsXV1VXsEIiIiCgDJu75xMZUjrpu1vgn9BWO3IrE503cxQ6JiIhIa8uXL9e67KhRowowEiIiInofE/d81K6ygypxv83EnYiIipclS5ZoVU4ikTBxJyIiKmRM3PNRu8r2mLX/Di6HvcKL2CTYmMrFDomIiEgr79/XTkREREWH1uO4W1lZwdra+oOTrlauXAk3NzcYGhqifv36+Oeff3Is/+bNG4wYMQKOjo6Qy+Xw9vbGwYMHdd5vQShnZYyqThZQCsDxOxzTnYiIKE1Jqu+JiIgKm9ZX3JcuXZrvO9+2bRvGjh2L1atXo379+li6dCnatWuHoKAg2NnZZSqfnJyMtm3bws7ODjt37oSTkxMePnwIS0vLfI8tt9pVtsfNiGgcuR2JPvVcxA6HiIgoVx4/foy9e/ciPDwcycnJGst8fX112lZJrO+JiIgKk0R4f5DWQlS/fn3UrVsXv/zyCwBAqVTC2dkZ3377LSZOnJip/OrVq7Fo0SIEBgZCX18/V/uMiYmBhYUFoqOjYW5unqf4sxIS9RZtfM/AQCbFv1PawNwwd3ESEVHpUdB1k678/f3RuXNneHh4IDAwEFWqVEFYWBgEQUCtWrVw4sQJnbZXEut7IiIiXeS1XtK6qXyahIQE7N27F4sXL8bixYuxb98+JCQk6Lzj5ORkXLlyBW3atEkPRipFmzZtcOHChSzX2bt3Lxo2bIgRI0bA3t4eVapUwdy5c6FQKLLdT1JSEmJiYjSmguRpZ4bytiZIVihxMjCqQPdFRERUECZNmoTx48fj5s2bMDQ0xK5du/Do0SM0b94cPXv21GlbJbW+JyIiKkw6Je579+6Fq6srunbtigkTJmDChAno0qULXF1dsW/fPp12/OLFCygUCtjb22vMt7e3R2RkZJbrPHjwADt37oRCocDBgwcxZcoU/Pzzz5g9e3a2+5k3bx4sLCzUk7Ozs05x5kb7Kg4AgCO3sz4OIiKiouzu3bsYOHAgAEBPTw8JCQkwNTXFzJkzsWDBAp22VZLreyIiosKideJ+/vx59OjRA82aNcO5c+fw6tUrvHr1CgEBAWjatCl69OiBixcvFmSsUCqVsLOzw9q1a1G7dm307t0bP/74I1avXp3tOpMmTUJ0dLR6evToUYHGCKiGhQOAU0HPkZiS/dUBIiKiosjExER9X7ujoyPu37+vXvbixYsC339xqe+JiIgKi9ad082ePRtDhgzBmjVrNOY3atQIjRo1wtdff42ZM2dq3eOrjY0NZDIZnj3T7H392bNncHBwyHIdR0dH6OvrQyaTqedVrFgRkZGRSE5OhoGBQaZ15HI55PLCHZatqpMFyloY4kl0Is7ee4G2lew/vBIREVER0aBBAwQEBKBixYro0KEDxo0bh5s3b2L37t1o0KCBTtsqyfU9ERFRYdH6ivvFixcxcuTIbJePGDEi23vVsmJgYIDatWvD399fPU+pVMLf3x8NGzbMcp3GjRsjJCQESqVSPS84OBiOjo5ZVuJikUgkaPeuufzhW2wuT0RExcOrV68AqHqNr1+/PgBgxowZaN26NbZt2wY3NzesX79ep22W5PqeiIiosGiduCckJOTY+52FhQUSExN12vnYsWOxbt06bNq0CXfv3sU333yDuLg4DBkyBAAwcOBATJo0SV3+m2++watXr/Ddd98hODgYBw4cwNy5czFixAid9lsY0prL+wc+Q4pC+YHSRERE4itbtiz69OmD+/fvo1q1agBUzeZXr16NGzduYNeuXXB1ddV5uyW5viciIioMWjeV9/LywokTJ9SV7Pv8/f3h5eWl08579+6N58+fY+rUqYiMjESNGjVw+PBhdQc24eHhkErTf1twdnbGkSNHMGbMGFSrVg1OTk747rvv8MMPP+i038JQ180aZUwM8DIuGf+EvkJjTxuxQyIiIsrRunXrsHHjRrRv3x7Ozs4YPHgwBg8eDDc3tzxttyTX90RERIVB63HclyxZgtmzZ2PLli3o0KGDxrIDBw5g0KBBmDx5MsaOHVsggeaXwhzXdeKuG9h6+REGNHDFrK5VCnRfRERUfBW1McdDQ0OxceNGbN68GY8ePULLli3xxRdfoFu3bsWmqXpRO6dERFS6Fdo47t999x1atWqFjh07omLFiujevTu6deuGChUqoHPnzmjevDlGjx6tcwAlWVpz+aN3IqFUavX7CBERkejc3d0xY8YMhIaG4vDhw7Czs8Pnn38OR0dHjBo1SuzwiIiISh2tE3epVIodO3bgzz//hI+PDwIDAxEUFIQKFSrgjz/+wK5duzSauRHQyLMMTOV6eBaThOuP34gdDhERkc7atGmDP/74A5s3bwYArFy5UuSIiIiISh+t73FP07t3b/Tu3bsgYilx5HoytKpgh73/PcGRW5Go5WIldkhERERae/jwIfz8/LBp0yZ1k/mhQ4eKHRYREVGpk2+XyK9evYqOHTvm1+ZKjLTm8kduR0LL7gSIiIhEk5SUhP/9739o06YNypcvDz8/PwwcOBAhISE4duwY+vTpI3aIREREpY5OifuRI0cwfvx4TJ48GQ8ePAAABAYGomvXrqhbt67GeKuk0sLHFgZ6UoS9jEfQs7dih0NERJSt4cOHw9HREZ9//jnKlCmDgwcPIiwsDDNmzMhzz/JERESUe1o3lV+/fj2+/PJLWFtb4/Xr1/jtt9/g6+uLb7/9Fr1798atW7dQsWLFgoy1WDKR66GZly2O332Gw7ciUcGBPdsSEVHRFBAQgGnTpqF///4oU6aM2OEQERHRO1pfcV+2bBkWLFiAFy9eYPv27Xjx4gV+/fVX3Lx5E6tXr2bSnoP2VVTN5Q/fihQ5EiIiouzduHED3333HZN2IiKiIkbrxP3+/fvo2bMnAKB79+7Q09PDokWLUK5cuQILrqRoU9EOMqkEgZFv8fBlnNjhEBERERERUTGideKekJAAY2NjAIBEIoFcLoejo2OBBVaSWBoboIGHNQBVJ3VERERERERE2tJpOLjffvsNpqamAIDU1FRs3LgRNjY2GmVGjRqVf9GVIO0rO+BcyEscvhWJr5qVFzscIiIiIiIiKiYkgpZjlLm5uUEikeS8MYlE3dt8URUTEwMLCwtER0fD3LzwOoqLjE5Eg3n+AIB/JreGnblhoe2biIiKNrHqpqykpqZi7ty5+Pzzz4v17XBF6ZwSERHltV7S+op7WFiYzhundA4WhqjpYolr4W9w5M4zDGjgKnZIREREmaT1YTNw4ECxQyEiIqJ3dBrHnfKmfWVV7/JH2Ls8EREVYa1atcLp06fFDoOIiIje0eked8qbdpUdMO9QIC4+eIk38cmwNDYQOyQiIqJMPv74Y0ycOBE3b95E7dq1YWJiorG8c+fOIkVGRERUOjFxL0RuNiao4GCGwMi38L8bhU9rF997B4mIqOQaPnw4AMDX1zfTMolEAoVCUdghERERlWpsKl/I2r1rLn+Yw8IREVERpVQqs52YtBMRERU+rRL3sWPHIi4uDgBw5swZpKamFmhQJVla4n4m+Dnik3keiYioaEtMTBQ7BCIiolJPq8R9xYoViI2NBQC0bNkSr169KtCgSrKKjmZwsTZGUqoSp4Oeix0OERFRJgqFArNmzYKTkxNMTU3VQ71OmTIF69evFzk6IiKi0kerxN3NzQ3Lly/H6dOnIQgCLly4gDNnzmQ5Uc4kEgnaV2FzeSIiKrrmzJmDjRs3YuHChTAwSO9ItUqVKvjtt99EjIyIiKh00qpzukWLFmHYsGGYN28eJBIJunXrlmU5dlijnXaVHbD2zAOcuBuF5FQlDPTY1QARERUdmzdvxtq1a9G6dWsMGzZMPb969eoIDAwUMTIiIqLSSauMsWvXroiMjERMTAwEQUBQUBBev36daWITeu3UdLaEnZkcb5NScf7+C7HDISIi0hAREQFPT89M85VKJVJSUkSIiIiIqHTT6VKvqakpTp48CXd3d1hYWGQ50YdJpRJ8VNkeAHCEzeWJiKiIqVSpEs6ePZtp/s6dO1GzZk0RIiIiIirddB7HvXnz5lAoFNi1axfu3r0LQFXBd+nSBTKZLN8DLKnaV3bE7xfDcfT2M8zuKkAmlYgdEhEREQBg6tSpGDRoECIiIqBUKrF7924EBQVh8+bN2L9/v9jhERERlTo631wdEhKCSpUqYeDAgdi9ezd2796NAQMGoHLlyrh//35BxFjiLDkWjMthr2BhpI+Xccm48vC1etly/3tYcixYxOiIiKi069KlC/bt24fjx4/DxMQEU6dOxd27d7Fv3z60bdtW7PCIiIhKHZ0T91GjRsHDwwOPHj3C1atXcfXqVYSHh8Pd3R2jRo0qiBhLHJlUgmX+91DW0hAAcPiWqrn8cv978D0WzKvvREQkuqZNm+LYsWOIiopCfHw8AgIC8NFHH4kdFhERUamkc1P506dP4+LFi7C2tlbPK1OmDObPn4/GjRvna3Al1ajWXgAA33dX1o/cjoSFkR6WHL+HsW291cuJiIjE4OHhgcuXL6NMmTIa89+8eYNatWqpx3UnIiKiwqHzFXe5XI63b99mmh8bG6sx1ivlbFRrL4xqpeqxN+JNApN2IiIqMsLCwrIc3jUpKQkREREiRERERFS66XzFvWPHjvjqq6+wfv161KtXDwBw6dIlDBs2DJ07d873AEuysR/54JeTIVAKgFQCJu1ERCSqvXv3qh8fOXJEY7QYhUIBf39/uLm5iRAZERFR6aZz4r58+XIMGjQIDRs2hL6+PgAgNTUVnTt3xrJly/I9wJJsuf89KAXVY6UALDgUiB8+riBuUEREVGp17doVACCRSDBo0CCNZfr6+nBzc8PPP/8sQmRERESlm86Ju6WlJf7++2+EhISoh4OrWLEiPD098z24kiytI7oxbbxw9M4z3H4Sg1Wn78PIQMYr70REJAqlUgkAcHd3x+XLl2FjYyNyRERERATkInFP4+npyWQ9l9KS9rR72h0sDPHDrpswN9JTd1jH5J2IiMQSGhqqfpyYmAhDQ0MRoyEiIiKdO6ejvFMoBY2O6DpXd4K5oR5iElLRraYTFGnt54mIiESgVCoxa9YsODk5wdTUVN2L/JQpU7B+/XqRoyMiIip9mLiLYMx7vccbGcjQs44zAOBNfDLGtPUWKzQiIiLMnj0bGzduxMKFCzVGjKlSpQp+++03ESMjIiIqnZi4FxH9G7gCAE4FP0f4y3iRoyEiotJs8+bNWLt2Lfr16weZTKaeX716dQQGBooYGRERUenExL2IcLcxQTNvWwgC8Pulh2KHQ0REpVhERESW/dgolUqkpKSIEBEREVHplqvE/ezZs+jfvz8aNmyIiIgIAMCWLVsQEBCQr8GVNgPfXXXf/u8jJKYoRI6GiIhKq0qVKuHs2bOZ5u/cuRM1a9YUISIiIqLSTede5Xft2oUBAwagX79+uHbtGpKSkgAA0dHRmDt3Lg4ePJjvQZYWLSvYwcnSCBFvErD3vyfo9e6+dyIiosI0depUDBo0CBEREVAqldi9ezeCgoKwefNm7N+/X+zwiIiISh2dr7jPnj0bq1evxrp166Cvr6+e37hxY1y9ejVfgyttZFKJ+l733y+yuTwREYmjS5cu2LdvH44fPw4TExNMnToVd+/exb59+9C2bVuxwyMiIip1dL7iHhQUhGbNmmWab2FhgTdv3uRHTKVarzrlsORYMG48jsb1R29Qw9lS7JCIiKgUatq0KY4dOyZ2GERERIRcXHF3cHBASEhIpvkBAQHw8PDIl6BKszKmcnSs5ggA2HwhTNxgiIio1IuNjUVMTIzGRERERIVL58T9yy+/xHfffYdLly5BIpHgyZMn+OOPPzB+/Hh88803BRFjqTOgoaq5/P4bT/EqLlnkaIiIqLQJDQ3FJ598AhMTE1hYWMDKygpWVlawtLSElZWV2OERERGVOjo3lZ84cSKUSiVat26N+Ph4NGvWDHK5HOPHj8e3335bEDGWOjWcLVHVyQI3I6Kx7fIjfNOivNghERFRKdK/f38IgoANGzbA3t4eEolE7JCIiIhKNYkgCEJuVkxOTkZISAhiY2NRqVIlmJqa5ndsBSImJgYWFhaIjo6Gubm52OFka/u/jzBh5w04WRrhzISWkEn5pYmIqKQqanWTqakprly5Ah8fH7FDybWidk6JiKh0y2u9pHNT+c2bN+Pu3bswMDBApUqVUK9ePZiamiIxMRGbN2/WOQDKWqdqZWFhpI+INwk4FRQldjhERFSK1K1bF48ePRI7DCIiInpH58R98ODBqFevHnbt2qUxPzo6GkOGDMm3wEo7IwMZetUpBwDYfIFDwxERUeH57bffsGDBAmzatAlXrlzBjRs3NCYiIiIqXDrf4w4AM2bMwIABA3Dz5k1Mnz49n0OiNP0buOK3gFCcDn6OsBdxcLMxETskIiIqBZ4/f4779+9r/CAvkUggCAIkEgkUCoWI0REREZU+Ol9xB1Sd1pw4cQJr1qxBjx49kJCQkN9xEQDXMiZo7m0LAPj9Iq+6ExFR4fj8889Rs2ZNXLhwAQ8ePEBoaKjGXyIiIipcOifuaT3LNmjQAJcuXUJISAgaNWqEsLCw/I6NAAx8NzTc9n8fISGZVziIiKjgPXz4EAsWLED9+vXh5uYGV1dXjYmIiIgKl86Je8ZO6F1cXHD+/Hm4ubmhbdu2+RoYqTT3tkM5KyPEJKZi738RYodDRESlQKtWrfDff/+JHQYRERG9o/M97tOmTdMY+s3Y2Bh79uzBtGnTcObMmXwNjgCZVIL+DVwx/1AgNl94iF51nDmeLhERFahOnTphzJgxuHnzJqpWrQp9fX2N5Z07dxYpMiIiotIp1+O4F1fFcVzXV3HJaDDPH8mpSuwe3gi1XKzEDomIiPJRUaubpNLsG+QVl87pito5JSKi0q1QxnHfu3cvUlJS1I+zm/bt26dzAACwcuVKuLm5wdDQEPXr18c///yj1Xpbt26FRCJB165dc7Xf4sLaxACdqpUFAGzh0HBERFTAlEpltlNuk3bW9URERLmnVVP5rl27IjIyEnZ2djlWnLn5FX7btm0YO3YsVq9ejfr162Pp0qVo164dgoKCYGdnl+16YWFhGD9+PJo2barT/oqrgQ1dsevqYxy48RQ/flIRNqZysUMiIiLSCut6IiKivBG9qXz9+vVRt25d/PLLLwBUv/I7Ozvj22+/xcSJE7NcR6FQoFmzZvj8889x9uxZvHnzBn/99ZdW+yvOTee6/BKA/x5H4/t2PhjR0lPscIiIKJ8UxbopLi4Op0+fRnh4OJKTkzWWjRo1SqdtFXZdDxTNc0pERKVXXuslnTuny0/Jycm4cuUKJk2apJ4nlUrRpk0bXLhwIdv1Zs6cCTs7OwwdOhRnz57NcR9JSUlISkpSP4+Jicl74CLp38AV/+28gf9dCsew5uUhk7KTOiIiyn/Xrl1Dhw4dEB8fj7i4OFhbW+PFixcwNjaGnZ2dTol7YdT1QMmq74mIiN6n9XBwFy5cwP79+zXmbd68Ge7u7rCzs8NXX32lUWFq48WLF1AoFLC3t9eYb29vj8jIyCzXCQgIwPr167Fu3Tqt9jFv3jxYWFioJ2dnZ51iLEo6VS8LS2N9RLxJgP/dZ2KHQ0REJdSYMWPQqVMnvH79GkZGRrh48SIePnyI2rVrY/HixTptqzDqeqBk1fdERETv0zpxnzlzJm7fvq1+fvPmTQwdOhRt2rTBxIkTsW/fPsybN69Agkzz9u1bDBgwAOvWrYONjY1W60yaNAnR0dHq6dGjRwUaY0Ey1Jehdx3VF5EtF9lJHRERFYzr169j3LhxkEqlkMlkSEpKgrOzMxYuXIjJkycX6L5zU9cDJau+JyIiep/WTeWvX7+OWbNmqZ9v3boV9evXV/8a7uzsjGnTpmH69Ola79zGxgYymQzPnmlePX727BkcHBwylb9//z7CwsLQqVMn9TylUqk6ED09BAUFoXz58hrryOVyyOUlpyO3/g1csfbsA5y99wIPnsfCw9ZU7JCIiKiE0dfXVw8JZ2dnh/DwcFSsWBEWFhY6J8SFUdcDJa++JyIiykjrK+6vX7/WaOZ2+vRpfPzxx+rndevW1bkyNzAwQO3ateHv76+ep1Qq4e/vj4YNG2YqX6FCBdy8eRPXr19XT507d0bLli1x/fr1UtEsztnaGC19VD3w/n4xXORoiIioJKpZsyYuX74MAGjevDmmTp2KP/74A6NHj0aVKlV02hbreiIiorzT+oq7vb09QkND4ezsjOTkZFy9ehUzZsxQL3/79i309fV1DmDs2LEYNGgQ6tSpg3r16mHp0qWIi4vDkCFDAAADBw6Ek5MT5s2bB0NDw0xfGCwtLQFA5y8SxdmABq44ERiFHVceYXw7bxgbiNrHIBERlTBz587F27dvAQBz5szBwIED8c0338DLywsbNmzQeXus64mIiPJG64yvQ4cOmDhxIhYsWIC//voLxsbGGuOq3rhxI8umax/Su3dvPH/+HFOnTkVkZCRq1KiBw4cPq6/uh4eHq5vrkUpzb1u4WBsj/FU8/r7+BJ/VcxE7JCIiKiEEQYCdnZ06Sbazs8Phw4fztE3W9URERHmj9TjuL168QPfu3REQEABTU1Ns2rQJ3bp1Uy9v3bo1GjRogDlz5hRYsPmhpIzruvbMfcw9GIiKjuY4OKoJJBIODUdEVFwVpbpJqVTC0NAQt2/fhpeXl6ix5EVROqdERESFNo67jY0Nzpw5g+joaJiamkImk2ks37FjB0xN2VFaYelVxxk/Hw3G3acxuBr+GrVdrcUOiYiISgCpVAovLy+8fPmyWCfuREREJYnO7dIsLCwyJe0AYG1tDQMDg3wJij7M71wYPO1UP5RsvqA5NNxy/3tYcixYjLCIiKgEmD9/Pr7//nvcunVL7FCIiIgIuUjcqWiQSSW4/SQGAHDw5lM8f5sEQJW0+x4LhkzKpvNERJQ7AwcOxD///IPq1avDyMgI1tbWGhMREREVLnZHXkyNaq1qvuh7LBgpCgHbLodDKaiej23rrV5ORESkq6VLl4odAhEREWXAxL0YG9XaC3eexODw7UgsPqpqGs+knYiI8mrQoEFih0BEREQZsKl8Mbe0Tw31Y5lUwqSdiIjyVWJiImJiYjQmIiIiKlxM3Iu5tWceqB8rlAKWHWendERElDdxcXEYOXIk7OzsYGJiAisrK42JiIiIChcT92IsrSO6b5qXh6G+6l+55Pg9LPe/J3JkRERUnE2YMAEnTpzAqlWrIJfL8dtvv2HGjBkoW7YsNm/eLHZ4REREpQ7vcS+m0pL2tHvaY5NSseXiQ7iXMYbvu6Hg2GyeiIhyY9++fdi8eTNatGiBIUOGoGnTpvD09ISrqyv++OMP9OvXT+wQiYiIShVecS+mFEpBoyO6oU3cIZEAoS/jMaihKxRKQeQIiYiouHr16hU8PDwAAObm5nj16hUAoEmTJjhz5oyYoREREZVKTNyLqTHv9R7vZmOCjyrZAwASU5QY09ZbrNCIiKiY8/DwQGhoKACgQoUK2L59OwDVlXhLS0sRIyMiIiqdmLiXIF81U10d2XMtAlFvE0WOhoiIiqshQ4bgv//+AwBMnDgRK1euhKGhIcaMGYPvv/9e5OiIiIhKH97jXoLUdrVGLRdLXA1/g83nH2J8Ox+xQyIiomJozJgx6sdt2rRBYGAgrly5Ak9PT1SrVk3EyIiIiEonXnEvYb5sqrrqvuXiQ8Qnp4ocDRERFSdKpRILFixA48aNUbduXUycOBEJCQlwdXVF9+7dmbQTERGJhIl7CfNRZQe4WBsjOiEFO688FjscIiIqRubMmYPJkyfD1NQUTk5OWLZsGUaMGCF2WERERKUeE/cSRiaV4Ium7gCA386Gsnd5IiLS2ubNm/Hrr7/iyJEj+Ouvv7Bv3z788ccfUCqVYodGRERUqjFxL4F61C4HCyN9hL+Kx9HbkWKHQ0RExUR4eDg6dOigft6mTRtIJBI8efJExKiIiIiIiXsJZGyghwENXAEA684+EDkaIiIqLlJTU2FoaKgxT19fHykpKSJFRERERAB7lS+xBjZyxdozD3A1/A2uPHyF2q7WYodERERFnCAIGDx4MORyuXpeYmIihg0bBhMTE/W83bt3ixEeERFRqcXEvYSyMzNEt5pO2PbvI6w98wBrBjBxJyKinA0aNCjTvP79+4sQCREREWXExL0E+6KpO7b9+whH7zxD2Is4uNmYfHglIiIqtfz8/MQOoVApFAreBkDFjr6+PmQymdhhEFEhY+JegnnZm6Gljy1OBj3H+oBQzOpaReyQiIiIRCcIAiIjI/HmzRuxQyHKFUtLSzg4OEAikYgdChEVEibuJdyXzTxwMug5dlx5hDFtvWFtYiB2SERERKJKS9rt7OxgbGzM5IeKDUEQEB8fj6ioKACAo6OjyBERUWFh4l7CNfQogypO5rgVEYPfLz7EqNZeYodEREQkGoVCoU7ay5QpI3Y4RDozMjICAERFRcHOzo7N5olKCQ4HV8JJJBJ82dQDALD5QhgSUxQiR0RERCSetHvajY2NRY6EKPfSXr/so4Go9GDiXgp0qOqIshaGeBGbjL+uRYgdDhERkejYPJ6KM75+iUofJu6lgL5Mis+buAMA1p19AKVSEDkiIiIiIiIi0hYT91Kid11nmMn1cP95HE4FR4kdDhERERUBGzduhKWlpdhh6KQ4xkxElFdM3EsJM0N9fFbfBQCw9swDkaMhIiIiXQ0ePBgSiSTT1L59e63Wd3Nzw9KlSzXm9e7dG8HBwQUQrSYm20REecNe5UuRwY3csCEgFBcfvMLNx9GoWs5C7JCIiIhIB+3bt4efn5/GPLlcnuvtGRkZqXspJyKiootX3EuRspZG6FS9LADVve5ERERUvMjlcjg4OGhMVlZWAFRjfE+fPh0uLi6Qy+UoW7YsRo0aBQBo0aIFHj58iDFjxqiv1AOZr4RPnz4dNWrUwIYNG+Di4gJTU1MMHz4cCoUCCxcuhIODA+zs7DBnzhyNuHx9fVG1alWYmJjA2dkZw4cPR2xsLADg1KlTGDJkCKKjo9X7nj59OgAgKSkJ48ePh5OTE0xMTFC/fn2cOnVKY9sbN26Ei4sLjI2N0a1bN7x8+fKD5+n8+fOoUaMGDA0NUadOHfz111+QSCS4fv06ANWwgEOHDoW7uzuMjIzg4+ODZcuWaWxj8ODB6Nq1K+bOnQt7e3tYWlpi5syZSE1Nxffffw9ra2uUK1dO44eUsLAwSCQSbN++HU2bNoWRkRHq1q2L4OBgXL58GXXq1IGpqSk+/vhjPH/+XL3e5cuX0bZtW9jY2MDCwgLNmzfH1atXP3icRFR6MHEvZb5oquqk7sDNp3j8Ol7kaIiIiIoAQQBS48SZhPzrMHbXrl1YsmQJ1qxZg3v37uGvv/5C1apVAQC7d+9GuXLlMHPmTDx9+hRPnz7Ndjv379/HoUOHcPjwYfz5559Yv349PvnkEzx+/BinT5/GggUL8NNPP+HSpUvqdaRSKZYvX47bt29j06ZNOHHiBCZMmAAAaNSoEZYuXQpzc3P1vsePHw8AGDlyJC5cuICtW7fixo0b6NmzJ9q3b4979+4BAC5duoShQ4di5MiRuH79Olq2bInZs2fneB5iYmLQqVMnVK1aFVevXsWsWbPwww8/aJRRKpUoV64cduzYgTt37mDq1KmYPHkytm/frlHuxIkTePLkCc6cOQNfX19MmzYNHTt2hJWVFS5duoRhw4bh66+/xuPHjzXWmzZtGn766SdcvXoVenp66Nu3LyZMmIBly5bh7NmzCAkJwdSpU9Xl3759i0GDBiEgIAAXL16El5cXOnTogLdv3+Z4rERUerCpfClTuawFGnuWwbmQl/A7F4YpHSuJHRIREZG4FPHAdlNx9t0rFtAz0br4/v37YWqqGevkyZMxefJkhIeHw8HBAW3atIG+vj5cXFxQr149AIC1tTVkMhnMzMzg4OCQ4z6USiU2bNgAMzMzVKpUCS1btkRQUBAOHjwIqVQKHx8fLFiwACdPnkT9+vUBAKNHj1av7+bmhtmzZ2PYsGH49ddfYWBgAAsLC0gkEo19h4eHw8/PD+Hh4ShbVtUicPz48Th8+DD8/Pwwd+5cLFu2DO3bt1f/CODt7Y3z58/j8OHD2cb/v//9DxKJBOvWrYOhoSEqVaqEiIgIfPnll+oy+vr6mDFjhvq5u7s7Lly4gO3bt6NXr17q+dbW1li+fLn6uBcuXIj4+HhMnjwZADBp0iTMnz8fAQEB6NOnj3q98ePHo127dgCA7777Dp999hn8/f3RuHFjAMDQoUOxceNGdflWrVppHMPatWthaWmJ06dPo2PHjjn8t4iotOAV91Loy6YeAICt/4QjOiFF5GiIiIhIWy1btsT169c1pmHDhgEAevbsiYSEBHh4eODLL7/Enj17kJqaqvM+3NzcYGZmpn5ub2+PSpUqQSqVasyLikofpeb48eNo3bo1nJycYGZmhgEDBuDly5eIj8++dd/NmzehUCjg7e0NU1NT9XT69Gncv38fAHD37l31jwNpGjZsmGP8QUFBqFatGgwNDdXz0n7AyGjlypWoXbs2bG1tYWpqirVr1yI8PFyjTOXKlTMdd1orBgCQyWQoU6aMxrkAgGrVqmmsA0BjvffP37Nnz/Dll1/Cy8sLFhYWMDc3R2xsbKZ4iKj04hX3Uqi5ty187M0Q9Owttv4Tjq+blxc7JCIiIvHIjFVXvsXatw5MTEzg6emZ5TJnZ2cEBQXh+PHjOHbsGIYPH45Fixbh9OnT0NfX13of75eVSCRZzlMqlQBU93V37NgR33zzDebMmQNra2sEBARg6NChSE5OhrFx1scYGxsLmUyGK1euQCaTaSx7v1VBftu6dSvGjx+Pn3/+GQ0bNoSZmRkWLVqk0fwf0P1cZLVeWn8C78/LuM6gQYPw8uVLLFu2DK6urpDL5WjYsCGSk5PzdqBEVGIwcS+FJBIJhjZ1x4SdN+B3LgxDGrvDQI+NL4iIqJSSSHRqrl6UGRkZoVOnTujUqRNGjBiBChUq4ObNm6hVqxYMDAygUCjyfZ9XrlyBUqnEzz//rL46/f694lntu2bNmlAoFIiKikLTpk2z3HbFihUzJdMXL17MMR4fHx/8/vvvSEpKUve4f/nyZY0y586dQ6NGjTB8+HD1vLSr/GI4d+4cfv31V3To0AEA8OjRI7x48UK0eIio6GG2Vkp1qVEWtmZyRMYkYv+NJ2KHQ0RERFpISkpCZGSkxpSW4G3cuBHr16/HrVu38ODBA/z+++8wMjKCq6srAFUT+DNnziAiIiJfk0JPT0+kpKRgxYoVePDgAbZs2YLVq1drlHFzc0NsbCz8/f3x4sULxMfHw9vbG/369cPAgQOxe/duhIaG4p9//sG8efNw4MABAMCoUaNw+PBhLF68GPfu3cMvv/yS4/3tANC3b18olUp89dVXuHv3Lo4cOYLFixcDSL/67eXlhX///RdHjhxBcHAwpkyZkim5L0xeXl7YsmUL7t69i0uXLqFfv34cpo+INDBxL6XkejIMbuQGAFh3NhRCPvZqS0RERAXj8OHDcHR01JiaNGkCALC0tMS6devQuHFjVKtWDcePH8e+fftQpkwZAMDMmTMRFhaG8uXLw9bWNt9iql69Onx9fbFgwQJUqVIFf/zxB+bNm6dRplGjRhg2bBh69+4NW1tbLFy4EADg5+eHgQMHYty4cfDx8UHXrl1x+fJluLi4AAAaNGiAdevWYdmyZahevTqOHj2Kn376Kcd4zM3NsW/fPly/fh01atTAjz/+qO7BPe2+96+//hrdu3dH7969Ub9+fbx8+VLj6nthW79+PV6/fo1atWphwIABGDVqFOzs7ESLh4iKHolQyjK2mJgYWFhYIDo6Gubm5mKHI6p5B+9iw7lQpCgE/D60Ppp42aiXLfe/B4VSwJi23iJGSERUOrBuyn/ZndPExESEhobC3d1do/MyKtn++OMP9VjyJeFKNl/HRMVPXut6XnEvxUzkekhRqH63WXv2gXr+cv978D0WDJlUIlZoRERERLm2efNmBAQEIDQ0FH/99Rd++OEH9OrVq0Qk7URUOrFzulJsVGsvRMenYP25UJwJfo7AyBgcvf0MvseCMbatN0a19hI7RCIiIiKdRUZGYurUqYiMjISjoyN69uyJOXPmiB0WEVGuMXEv5aZ0qoSz954jOCoWHy87C0EAk3YiIiIq1iZMmIAJEyaIHQYRUb5hU3nCir61AACCAMgkEibtRERERERERQgTd8KR25HqxwpBwPgd/4kYDREREREREWXExL2US+uIbmxbb/Su4wwA2HnlMeYcuCNyZERERERERATwHvdSLWPSPqq1FxJTFLj1JBq3n8Rg3dlQGBvocTg4IiIiIiIikfGKeymmUAoaHdEZ6suwql9tmBuqfs85FRQlZnhEREREREQEJu6l2pgseo93KWOMpX1qAAD+exyNv65FiBAZERERERERpWHiTpm0qmCPb1t5AgAm7b6JoMi3IkdEREREBWHjxo2wtLQUOwydFMeYiYjyiok7ZWl0G2809bJBQooC3/x+BW8TU8QOiYiIqFQbPHgwJBJJpql9+/Zare/m5oalS5dqzOvduzeCg4MLIFpNTLaJiPKmSCTuK1euhJubGwwNDVG/fn38888/2ZZdt24dmjZtCisrK1hZWaFNmzY5lqfckUklWNanJspaGOLBizh8v+MGBEEQOywiIiqmWNfnj/bt2+Pp06ca059//pnr7RkZGcHOzi4fIyQiooIgeuK+bds2jB07FtOmTcPVq1dRvXp1tGvXDlFRWXeMdurUKXz22Wc4efIkLly4AGdnZ3z00UeIiOC92PnN2sQAK/vVgr5MgsO3I/Hb2VCxQyIiomKoqNf1ggDExYkz6fqbuFwuh4ODg8ZkZWX17jgETJ8+HS4uLpDL5ShbtixGjRoFAGjRogUePnyIMWPGqK/UA5mvhE+fPh01atTAhg0b4OLiAlNTUwwfPhwKhQILFy6Eg4MD7OzsMGfOHI24fH19UbVqVZiYmMDZ2RnDhw9HbGwsANX/c8iQIYiOjlbve/r06QCApKQkjB8/Hk5OTjAxMUH9+vVx6tQpjW1v3LgRLi4uMDY2Rrdu3fDy5cscz1FYWBgkEgm2bt2KRo0awdDQEFWqVMHp06d1O9lEREWJILJ69eoJI0aMUD9XKBRC2bJlhXnz5mm1fmpqqmBmZiZs2rRJq/LR0dECACE6OjpX8ZZGmy+ECa4/7Bc8Jh0QLt5/IXY4REQlTkmvmwq7rheE7M9pQkKCcOfOHSEhIUE9LzZWEFQpdOFPsbFaH5IwaNAgoUuXLtku37Fjh2Bubi4cPHhQePjwoXDp0iVh7dq1giAIwsuXL4Vy5coJM2fOFJ4+fSo8ffpUEARB8PPzEywsLNTbmDZtmmBqair06NFDuH37trB3717BwMBAaNeunfDtt98KgYGBwoYNGwQAwsWLF9XrLVmyRDhx4oQQGhoq+Pv7Cz4+PsI333wjCIIgJCUlCUuXLhXMzc3V+3779q0gCILwxRdfCI0aNRLOnDkjhISECIsWLRLkcrkQHBwsCIIgXLx4UZBKpcKCBQuEoKAgYdmyZYKlpaVGzO8LDQ0VAAjlypUTdu7cKdy5c0f44osvBDMzM+HFi5LxPSar1zERFW15retFveKenJyMK1euoE2bNup5UqkUbdq0wYULF7TaRnx8PFJSUmBtbZ3l8qSkJMTExGhMpJv+9V3QraYTFEoBI/53DVExiWKHRERExURh1PVA6anv9+/fD1NTU41p7ty5AIDw8HA4ODigTZs2cHFxQb169fDll18CAKytrSGTyWBmZqa+Up8dpVKJDRs2oFKlSujUqRNatmyJoKAgLF26FD4+PhgyZAh8fHxw8uRJ9TqjR49Gy5Yt4ebmhlatWmH27NnYvn07AMDAwAAWFhaQSCTqfZuamiI8PBx+fn7YsWMHmjZtivLly2P8+PFo0qQJ/Pz8AADLli1D+/btMWHCBHh7e2PUqFFo166dVudq5MiR+PTTT1GxYkWsWrUKFhYWWL9+fa7OOxGR2PTE3PmLFy+gUChgb2+vMd/e3h6BgYFabeOHH35A2bJlNb4QZDRv3jzMmDEjz7GWZhKJBHO7VcXdpzEIjHyLEf+7iv992QD6MtHvtCAioiKuMOp6IG/1vbEx8K5Vd6EzNtatfMuWLbFq1SqNeWk/aPTs2RNLly6Fh4cH2rdvjw4dOqBTp07Q09Pt656bmxvMzMzUz+3t7SGTySCVSjXmZbzV4fjx45g3bx4CAwMRExOD1NRUJCYmIj4+HsbZHOTNmzehUCjg7e2tMT8pKQllypQBANy9exfdunXTWN6wYUMcPnz4g8fRsGFD9WM9PT3UqVMHd+/e/eB6RERFkaiJe17Nnz8fW7duxalTp2BoaJhlmUmTJmHs2LHq5zExMXB2di6sEEsMIwMZVvWvjc4rAnA57DUWHArETx0riR0WERGVcNrU9UDe6nuJBDAxyXOohcLExASenp5ZLnN2dkZQUBCOHz+OY8eOYfjw4Vi0aBFOnz4NfX19rffxflmJRJLlPKVSCUB1T3nHjh3xzTffYM6cObC2tkZAQACGDh2K5OTkbBP32NhYyGQyXLlyBTKZTGOZqamp1vESEZUGol4ytbGxgUwmw7NnzzTmP3v2LMcmXACwePFizJ8/H0ePHkW1atWyLSeXy2Fubq4xUe6425hgUc/qAIDfAkJx8OZTkSMiIqKirjDqeoD1fRojIyN06tQJy5cvx6lTp3DhwgXcvHkTgKrJukKhyPd9XrlyBUqlEj///DMaNGgAb29vPHnyRKNMVvuuWbMmFAoFoqKi4OnpqTGlvTYqVqyIS5cuaax38eJFreLKWC41NRVXrlxBxYoVc3OIRESiEzVxNzAwQO3ateHv76+ep1Qq4e/vr9G86X0LFy7ErFmzcPjwYdSpU6cwQqV32ldxwNfNPQAA3+/4DyFRIrUtJCKiYoF1ff5KSkpCZGSkxvTixQsAqt7X169fj1u3buHBgwf4/fffYWRkBFdXVwCqJvBnzpxBRESEep384OnpiZSUFKxYsQIPHjzAli1bsHr1ao0ybm5uiI2Nhb+/P168eIH4+Hh4e3ujX79+GDhwIHbv3o3Q0FD8888/mDdvHg4cOAAAGDVqFA4fPozFixfj3r17+OWXX7RqJg+ohiDcs2cPAgMDMWLECLx+/Rqff/55vh03EVFhEv0m5bFjx2LdunXYtGkT7t69i2+++QZxcXEYMmQIAGDgwIGYNGmSuvyCBQswZcoUbNiwAW5ubupKK1asm9NKoe8/8kEDD2vEJSvwze9XEJeUKnZIRERUhLGuzz+HDx+Go6OjxtSkSRMAgKWlJdatW4fGjRujWrVqOH78OPbt26e+X3zmzJkICwtD+fLlYWtrm28xVa9eHb6+vliwYAGqVKmCP/74A/PmzdMo06hRIwwbNgy9e/eGra0tFi5cCADw8/PDwIEDMW7cOPj4+KBr1664fPkyXFxcAAANGjTAunXrsGzZMlSvXh1Hjx7FTz/9pFVc8+fPx/z581G9enUEBARg7969sLGxybfjJiIqTBJB0HUE0fz3yy+/YNGiRYiMjESNGjWwfPly1K9fH4Bq3FE3Nzds3LgRgOoX24cPH2baxrRp09RjguYkJiYGFhYWiI6OLrXN6PLD87dJaL7oJOKTFehUvSyW96mhHhMWAJb734NCKWBMW+8ctkJEREDpqJsKs64Hsj+niYmJCA0Nhbu7e473zFPxFRYWBnd3d1y7dg01atQQO5wCwdcxUfGT17q+SHRON3LkSIwcOTLLZadOndJ4HhYWVvAB0QfZmsnRqXpZbLv8CPv+e4LaLpYY3NgdgCpp9z0WjLFM2omI6B3W9URERLlXJBJ3Kp4WfFoNkdGJOB38HDP330HVchY4F/JSnbSPau0ldohERERERETFHhN3ypONQ+qi3dIzCH4Wi09XXQAAJu1EREQkGjc3NxSBO0GJiPKV6J3TUfEmkUiwe3hjjXnlbTn2KhERERERUX5h4k55tiEgFACQ1jXdiP9dxeQ9N5GYkv9jxRIREREREZU2TNwpTzJ2RBc852PUc7cCAPzvUji6rjyHkKi3IkdIRERERERUvDFxp1zLmLSPau0FfZkU279uhE9rOQEAAiPfotOKc9h++RHvNSMiIiIiIsolJu6UawqlkGVHdD/3qoGvm3nAxdoICSkKTNh1A6O3XUdsUqpIkRIRERERERVfTNwp18bk0Hv8pA4VcWp8S3zfzgcyqQR/X3+CjsvP4ubj6EKOkoiIiIiIqHhj4k4FRiqVYERLT2z/ugGcLI0Q9jIe3Vedw4aAUDadJyIiIiIi0hITdypwtV2tcWBUE3xUyR4pCgEz99/Bl5uv4HVcstihERERFQsSiSTHafr06YUaT0hICD7//HO4uLhALpfDyckJrVu3xh9//IHUVN4aR0SU3/TEDoBKB0tjA6wZUBubLzzEnAN3cfzuM3RYfhbLP6uJum7WYodHRERUpD19+lT9eNu2bZg6dSqCgoLU80xNTdWPBUGAQqGAnl7BfM37559/0KZNG1SuXBkrV65EhQoVAAD//vsvVq5ciSpVqqB69eoFsm8iotKKV9yp0EgkEgxq5IbdwxvB3cYET6MT0Wv1BfRbdxEKZeam88v972HJsWARIiUiolIpNS77SZGofdnUBO3K6sDBwUE9WVhYQCKRqJ8HBgbCzMwMhw4dQu3atSGXyxEQEIDBgweja9euGtsZPXo0WrRooX6uVCoxb948uLu7w8jICNWrV8fOnTuzjUMQBAwePBje3t44d+4cOnXqBC8vL3h5eeGzzz5DQEAAqlWrpi7/ww8/wNvbG8bGxvDw8MCUKVOQkpKiXj59+nTUqFEDGzZsgIuLC0xNTTF8+HAoFAosXLgQDg4OsLOzw5w5czTikEgkWLNmDTp27AhjY2NUrFgRFy5cQEhICFq0aAETExM0atQI9+/fV69z//59dOnSBfb29jA1NUXdunVx/Phxnf4PRERi4RV3KnRVnCyw79smmPrXLey+FoFz91+i5eKT2DmsEezMDQFoDjVHRERUKLabZr+sbAegxYH057vsAEV81mXtmgNtTqU//9sNSHqRuVzf/O3vZeLEiVi8eDE8PDxgZWWl1Trz5s3D77//jtWrV8PLywtnzpxB//79YWtri+bNm2cqf/36ddy9exd//vknpNKsr/9IJBL1YzMzM2zcuBFly5bFzZs38eWXX8LMzAwTJkxQl7l//z4OHTqEw4cP4/79++jRowcePHgAb29vnD59GufPn8fnn3+ONm3aoH79+ur1Zs2aBV9fX/j6+uKHH35A37594eHhgUmTJsHFxQWff/45Ro4ciUOHDgEAYmNj0aFDB8yZMwdyuRybN29Gp06dEBQUBBcXF63OFxGRWJi4kyhM5Xrw7V0DjT1tMHH3DYS/SkCLxaewsl8t3HwcrTE+PBEREX3YzJkz0bZtW63LJyUlYe7cuTh+/DgaNmwIAPDw8EBAQADWrFmTZeIeHKxqCefj46OeFxUVBQ8PD/XzhQsXYvjw4QCAn376ST3fzc0N48ePx9atWzUSd6VSiQ0bNsDMzAyVKlVCy5YtERQUhIMHD0IqlcLHxwcLFizAyZMnNRL3IUOGoFevXgBUV/YbNmyIKVOmoF27dgCA7777DkOGDFGXr169ukYT/lmzZmHPnj3Yu3cvRo4cqfV5IyISAxN3EtWntcuhhosleq+5gBexyRjidxkAMLiRK5N2IiIqXL1is18mkWk+/zQqhw29dyW6S1huI9JJnTp1dCofEhKC+Pj4TMl+cnIyatasqfV2ypQpg+vXrwMAWrRogeTk9M5nt23bhuXLl+P+/fuIjY1FamoqzM3NNdZ3c3ODmZmZ+rm9vT1kMpnGFX17e3tERWme84xN8u3t7QEAVatW1ZiXmJiImJgYmJubIzY2FtOnT8eBAwfw9OlTpKamIiEhAeHh4VofKxGRWJi4k+jK25oi4IdWqDT1MNJudd9yMRzJCgFj2njD1kwuboBERFQ66JmIXzYPTEw09yOVSjMNv5rx/vLYWNUPFQcOHICTk5NGObk867rXy0v1o3pQUJA6uZfJZPD09AQAjQ7xLly4gH79+mHGjBlo164dLCwssHXrVvz8888a29TX19d4LpFIspynVCqzXS+teX5W89LWGz9+PI4dO4bFixfD09MTRkZG6NGjh8YPDURERRUTdyoS1p55AKUA6MskSFEIUCgF/O9SOP6+FoGvm5fHF03dYWzAlysREZG2bG1tcevWLY15169fVye3lSpVglwuR3h4eJbN4rNSs2ZNVKhQAYsXL0avXr2yvc8dAM6fPw9XV1f8+OOP6nkPHz7MxZHkj3PnzmHw4MHo1q0bANUPF2FhYaLFQ0SkC/YqT6LL2BHdvTkd1B3SOZgbIi5ZAd9jwWi5+BS2//soy97niYiIKLNWrVrh33//xebNm3Hv3j1MmzZNI5E3MzPD+PHjMWbMGGzatAn379/H1atXsWLFCmzatCnLbUokEvj5+SEoKAiNGzfG3r17ce/ePdy5cwerV6/G8+fPIZOpbivw8vJCeHg4tm7divv372P58uXYs2dPoRx7Vry8vLB7925cv34d//33H/r27ZvpKj4RUVHFxJ1ElTFpT7unfVRrL4xt643ImER8UtUR5ayM8CwmCRN23sAny8/iTPBzkaMmIiIq+tq1a4cpU6ZgwoQJqFu3Lt6+fYuBAwdqlJk1axamTJmCefPmoWLFimjfvj0OHDgAd3f3bLfboEEDXLlyBT4+PhgxYgQqVaqERo0a4c8//8SSJUvwzTffAAA6d+6MMWPGYOTIkahRowbOnz+PKVOmFOgx58TX1xdWVlZo1KgROnXqhHbt2qFWrVqixUNEpAuJ8P7NTyVcTEwMLCwsEB0dnalzFCp8S44FQyaVZNkR3XL/e1AoBQxvWR6bzz/EihP3EJOYCgBo6mWDyR0qoqIj/4dEVPyxbsp/2Z3TxMREhIaGwt3dHYaGhiJGSJR7fB0TFT95ret50zCJakwO47RnTOa/bOaBnnXKYcWJEGy+EIaz916gw/Kz6FGrHMyN9GFhpJ9j8p/TfoiIiIiIiIoyJu5UbFgaG2BKx0oY2NAVC48E4cCNp9hx5TH0pBKkKgUkpyoxvl36uLIZm+ETEREREREVV7zHnYod1zImWNm3FnYPb4Q6rlZIfddh3S8nQzB042WkKpRZ3jtPRERERERUHPGKOxVbtVyssGNYQxy5HYn5hwIR9jIe/oFR8PzxEABgYENXJu1ERERERFTs8Yo7FWsSiQTtqzji6JjmmN6pksayzRce4pPlZ7E+IBQvYpNEipCIiIiIiChveMWdSgQDPam6x/m0e96lEuD2kxjcfnIHcw/eRQtvW3xauxxaVbCDob5M5IiJiIiIiIi0w8SdSoT372lPe96qgi1exqXgv0dv4B8YBf/AKJgb6qFj9bL4tFY51HKxxNLj9z44JB17pSciIiIiIrEwcadiL6uO6NL+ps3/uWd17L76GHuuReBpdCL+dykc/7sUDrcyxihraYTz919qrPf+domIiIiIiMTCxJ2KPYVSyLL3+LTnCqUATztTTGhfAeM/8sHFBy+x8+pjHL4VibCX8Qh7GQ9AleTfiojGz72qw+9cGHulJyIiIiKiIoGJOxV7OTVjfz/plkolaORpg0aeNpjVJRVHbkdi19XHOH//JQQBOHrnGapOPwoA6F7LCSNaehZo7ERERERERB/CXuWp1DKR66F7rXL444sGOPdDK0xo76OxfPfVCDSa7495B+8i+NlbkaIkIiJSjaKS0zR9+nSxQyQiogLEK+5EAMpaGiFVIQBI75XeUF+KZzFJWHPmAdaceYAqTub4tFY5dK5eFmVM5SJHTEREpcnTp0/Vj7dt24apU6ciKChIPc/U1FT9WBAEKBQK6Onxax4RUUnBK+5E0OyILmRuB4xt643EFCU6VSuLjyrZQ18mwa2IGMzYdwf15/rji02XcejmUySlKgAAS44FY7n/vWy3veRYcGEeDhER5UJcXPZTYqL2ZRMStCurCwcHB/VkYWEBiUSifh4YGAgzMzMcOnQItWvXhlwuR0BAAAYPHoyuXbtqbGf06NFo0aKF+rlSqcS8efPg7u4OIyMjVK9eHTt37swxFjc3N8yaNQufffYZTExM4OTkhJUrV+p2QEREpBP+FEulnja90s//tBr2/fcEu68+xn+Po3H8bhSO342ChZE+OlV3RKpSwNZ/Hmms+/62iYioaMtw0TqTDh2AAwfSn9vZAfHxWZdt3hw4dSr9uZsb8OJF5nKCkJsoszdx4kQsXrwYHh4esLKy0mqdefPm4ffff8fq1avh5eWFM2fOoH///rC1tUXz5s2zXW/RokWYPHkyZsyYgSNHjuC7776Dt7c32rZtm1+HQ0REGTBxp1JPm17prU0MMKiRGwY1ckNI1FvsuhqBPVcjEBmTiN8vhgMArIz14XssGDEJKfipY6UsfxAgIiIqKDNnztQpcU5KSsLcuXNx/PhxNGzYEADg4eGBgIAArFmzJsfEvXHjxpg4cSIAwNvbG+fOncOSJUuYuBMRFRAm7lTq6dIrPQB42pnhh3dDy124/xK7rz7GoVuReB2fAgD4LSAU6wNCIQBoW9EOLXxskZiigKG+LMc4lhwLhkwqyXKfy/3vQaEUcoyViIjyJjY2+2Wy9z7Co6KyLyt970bEsLBch6STOnXq6FQ+JCQE8fHxmZLt5ORk1KxZM8d10xL9jM+XLl2q0/6JiEh7TNyJcun/7d19VFTlvgfw78wI40DA8D6DIqJwEDKxVEbK3tQEO7miOGuZx2o0T10NXQqZ5+gNyVtdztFyeSuXXu/tZbkKNVppK63OJVM7KmrioeKIJIhhyYtvvMuLzHP/QLduGRSY0b1n+H7W2itmz97P/OZZT+vnb/bz7K3TajAhOggTooPwWsolfFVUhc+uPFru8jF5xTXIK66BVgMMC74DsWZfxJp9EGv2xZ1mXwT76KHRaKT2Vl9eC8/p9kREt5+3t/LHOsL7ug/SarUQ183Hb29vl/5uvPxLxY4dOzBo0CDZcXo9b8JKRKQmLNyJnMBbPwB/GDMYp2svYn/ZOei0GnTYBIYEeKGx9RLON7WhtKYRpTWN+OKHq+cFenvKivlnxkfIindOtycior4KDg5GUVGRbF9hYSE8PDwAAHFxcdDr9aioqLjhtHh7Dhw40OV1bGysYwETEVG3WLgTOcn1RfaV1+mTo/FUwhAcraxHcWU9iisbcPR0HcrPNuFcUxv2lp7F3tKrdy3SaTqvvK/55mfYBPCHMYPxbGJEj2LgdHsiIrpi4sSJWLVqFTZu3IjExER89NFHKCoqkqbB+/j4YPHixUhPT4fNZsOECRNQV1eHffv2wdfXF1artdu29+3bh5UrVyIlJQV5eXnIzc3Fjmvv3kdERE7Fwp3ICW52Z3qNprOYfjgmRDrnYlsHfq5uQHFlvVTUH6tsQEPrJQCA7fLsxk8LfsWnBb/C7DdQujofZ/ZDrNkHEYHe0Gk1Upucbk9ERFckJSUhMzMTS5YsQUtLC5577jk8++yz+Omnn6RjXnvtNQQHByM7OxsnTpyA0WjEPffcg2XLlt2w7ZdeegmHDx/GihUr4Ovri9WrVyMpKelWfyUion5LI65f/OTm6uvr4efnh7q6Ovj6+iodDrkJZ13pFkLg9R3FeG9vOXQaDTqEgK9hAOovXrJ7vMFDhxiTD+LCfBFr9kWc2Qe7jp3Bu7tKu1z553R7IvVibnK+7vq0paUF5eXliIyMxMCBAxWM0HUNHToUixYtwqJFi5QOpd/iOCZyPY7mel5xJ3KC3t6ZvjvvfFuK9/aWdym60x4ejodiQjqvzp/uvDpfUt2Ai+0dKDxVi8JTtbJ2/Aydj6b7r2+Oo0MI/GlCJBZMjLrp5zvjBwhO1yciIiIici4W7kQqcbPp9voBOlkx3GETKD/bdHnd/NXp9tX1rai72HnX4I7LE2r+d285Pjl86vJUe1/EXf5vdOgdssfUOWOqPafrExERERE5Fwt3IpXosAm709mvvO6wyVe16LQaRIXcgaiQOzAtPkzaf76pDf/5ZTE+LfgVWk3nWnmtBqhvuYSD5edxsPy8rI3hwd5SQR8fbsS/PTDMoTvbX/tjQ1/bICIi9Tp5ux5MT0REEq5xJ3Iz3d3d/unxEbg73HjN3e3rcaG53W4bXp46NLd1SIX/PUOMGB3u36s4Ck9dwJGKWmmt/p/uj8S/PxorPbeeiK5ibnI+rnEnd8ZxTOR6uMadiCQ3m24f4qNH5mNxADpvhFdd3ypNs79S0JefbUJzWweAq3e2P1JRiyMVtX2KSZqu/49yfPK9fLp+XJgvokLk0/UBrpMnoluvn123IDfD8UvU/7BwJ3IjvZlur9FoYPIbCJPfQDw8Qv6Yuv/YfhSbDlVIV9wThvpj7NCAXsVy+OR5HDp5oVfT9a+svW9p78B/f3dCFjvAdfJE5DgPDw8AQHNzMwwGg8LREPVNc3MzgKvjmYjcHwt3IjfijLvb/88/TmDToYouU+0nRAf3uI23dx7HoZMX7EzXH4LR4f6yG+rVNrfj5+pG/FzdiM8LT0tteHnqsDrvZ3z38xk8kxiBgl8uYGP+L1wnT0QO0el0MBqNqKmpAQB4eXlxCQ+5DCEEmpubUVNTA6PRCJ1Od/OTiMgtsHAnIsnNptpf+7qvbYT4DJRN16+qb7lcyDfYna5/+JcLOPzLBQCdV+f/72gVfr3QLE25jzX7ws8gv+KglsfaqaENNcTA70FqYzKZAEAq3olcjdFolMYxEfUPLNyJSNLbO9s72oZGo4HZzwCznwETR4RK+5vbLqGkqgHFlQ14ZdtP0lr7DptA0W/1KPqtXtb2IKPh8lR7H8SafdHQ0o73952UfS5w+x9rp4Y21BADvwepjUajgdlsRkhICNrb7d+kk0itPDw8eKWdqB/iXeWJSLWuFEOeOi3aOmx47r6hSIgMwNHKBhw93Xl1/rfai3bP9dBp0N4hMGqwH568exD2lp7FN8U1mBwbIvuR4Ea+PVYtO+f6167ShhpicNfv8cTdg1F2ptHhxx0yNzkf+5SIiNTE0bykisJ97dq1WLVqFaqqqhAfH4933nkHCQkJ3R6fm5uLzMxMnDx5EtHR0fjb3/6GRx99tEefxURO5Bq6e6zd9cVR3cV2HLtmzXxxZQNKqhvQdsmmYPTUX2gACMDhey/0h9x0O3M90D/6lIiIXIfLPw5uy5YtyMjIwPr162GxWLBmzRokJSWhpKQEISEhXY7fv38/ZsyYgezsbDz22GPIyclBSkoKjhw5gpEjRyrwDYjI2Xqz1t7P4AHLsEBYhgVK51/qsKH8bBOOVtYjfUshbALQaIBHYnt2RfV6ecXVEG7QhhpicEYbaojh2jY8dVreMPEmmOuJiIgco/gVd4vFgnHjxuHdd98FANhsNoSHh2PBggX4y1/+0uX46dOno6mpCdu3b5f2jR8/HqNHj8b69etv+nn8BZ5I/Zx1A7Drp9r35aqou7Shhhj4Pbrn7rnpdud6wP37lIiIXItLX3Fva2tDQUEBli5dKu3TarWYPHky8vPz7Z6Tn5+PjIwM2b6kpCRs27bN7vGtra1obW2VXtfV1QHo7DgiUqc5ls475dr7/3TWuNBu37vW+t1leHdXKeY/HIW5Dw3H+t1leHN7IVqaGjH3oeE9isNd2lBDDPweN3ZlPKtg9ZrT3Y5cDzDfExGRujmc64WCfvvtNwFA7N+/X7b/5ZdfFgkJCXbP8fDwEDk5ObJ9a9euFSEhIXaPz8rKEuhcgsiNGzdu3Lipejt16pRzEqyK3I5cLwTzPTdu3Lhxc42tr7le8TXut9rSpUtlv9rbbDacP38egYGB0Gg0DrVdX1+P8PBwnDp1itPwnID96VzsT+dhXzoX+7MrIQQaGhoQFhamdCgui/levdh/jmH/OYb95xj2n2Ou7T8fHx+Hcr2ihXtQUBB0Oh2qq6tl+6urq2EymeyeYzKZenW8Xq+HXq+X7TMajX0P2g5fX18OZCdifzoX+9N52JfOxf6U8/PzUzqEW+J25HqA+d4VsP8cw/5zDPvPMew/x1zpP0dyvdaJ8fSap6cnxowZg507d0r7bDYbdu7cicTERLvnJCYmyo4HgLy8vG6PJyIiIuUw1xMRETlO8anyGRkZsFqtGDt2LBISErBmzRo0NTVh9uzZAIBnn30WgwYNQnZ2NgBg4cKFePDBB/HWW2/h97//PTZv3ozDhw9jw4YNSn4NIiIi6gZzPRERkWMUL9ynT5+OM2fOYPny5aiqqsLo0aPx9ddfIzS0887RFRUV0GqvTgy49957kZOTg1deeQXLli1DdHQ0tm3bpshzXfV6PbKysrpMzaO+YX86F/vTediXzsX+7H9cOdcDHLOOYv85hv3nGPafY9h/jnFm/yn+HHciIiIiIiIi6p6ia9yJiIiIiIiI6MZYuBMRERERERGpGAt3IiIiIiIiIhVj4U5ERERERESkYizcHbB27VoMHToUAwcOhMViwaFDh5QOySW9+uqr0Gg0sm3EiBFKh+USvvvuO0ybNg1hYWHQaDTYtm2b7H0hBJYvXw6z2QyDwYDJkyfj+PHjygTrAm7Wn7NmzeoyVpOTk5UJVuWys7Mxbtw4+Pj4ICQkBCkpKSgpKZEd09LSgrS0NAQGBuKOO+5AamoqqqurFYqYyD7m+r5jfu8d5nTHMIf3HXO2Y3rSfw899FCX8Td37txefQ4L9z7asmULMjIykJWVhSNHjiA+Ph5JSUmoqalROjSXdOedd6KyslLa9u7dq3RILqGpqQnx8fFYu3at3fdXrlyJt99+G+vXr8fBgwfh7e2NpKQktLS03OZIXcPN+hMAkpOTZWN106ZNtzFC17Fnzx6kpaXhwIEDyMvLQ3t7O6ZMmYKmpibpmPT0dHzxxRfIzc3Fnj17cPr0aTz55JMKRk0kx1zvOOb3nmNOdwxzeN8xZzumJ/0HAM8//7xs/K1cubJ3HySoTxISEkRaWpr0uqOjQ4SFhYns7GwFo3JNWVlZIj4+XukwXB4AsXXrVum1zWYTJpNJrFq1StpXW1sr9Hq92LRpkwIRupbr+1MIIaxWq3j88ccVicfV1dTUCABiz549QojOsejh4SFyc3OlY4qLiwUAkZ+fr1SYRDLM9Y5hfu875nTHMIc7hjnbMdf3nxBCPPjgg2LhwoUOtcsr7n3Q1taGgoICTJ48Wdqn1WoxefJk5OfnKxiZ6zp+/DjCwsIwbNgwzJw5ExUVFUqH5PLKy8tRVVUlG6d+fn6wWCwcpw7YvXs3QkJCEBMTg3nz5uHcuXNKh+QS6urqAAABAQEAgIKCArS3t8vG54gRIzBkyBCOT1IF5nrnYH53DuZ052AO7xnmbMdc339XfPzxxwgKCsLIkSOxdOlSNDc396rdAU6LsB85e/YsOjo6EBoaKtsfGhqKY8eOKRSV67JYLPjwww8RExODyspKrFixAvfffz+Kiorg4+OjdHguq6qqCgDsjtMr71HvJCcn48knn0RkZCTKysqwbNkyTJ06Ffn5+dDpdEqHp1o2mw2LFi3Cfffdh5EjRwLoHJ+enp4wGo2yYzk+SS2Y6x3H/O48zOmOYw7vGeZsx9jrPwD44x//iIiICISFheHHH3/En//8Z5SUlOCzzz7rcdss3ElxU6dOlf4eNWoULBYLIiIi8Mknn2DOnDkKRkYk99RTT0l/33XXXRg1ahSGDx+O3bt3Y9KkSQpGpm5paWkoKiri2laifob5ndSEObxnmLMd013/vfDCC9Lfd911F8xmMyZNmoSysjIMHz68R21zqnwfBAUFQafTdbmTYnV1NUwmk0JRuQ+j0Yjf/e53KC0tVToUl3ZlLHKc3jrDhg1DUFAQx+oNzJ8/H9u3b8euXbswePBgab/JZEJbWxtqa2tlx3N8klow1zsf83vfMac7H3N4V8zZjumu/+yxWCwA0Kvxx8K9Dzw9PTFmzBjs3LlT2mez2bBz504kJiYqGJl7aGxsRFlZGcxms9KhuLTIyEiYTCbZOK2vr8fBgwc5Tp3k119/xblz5zhW7RBCYP78+di6dSu+/fZbREZGyt4fM2YMPDw8ZOOzpKQEFRUVHJ+kCsz1zsf83nfM6c7HHH4Vc7ZjbtZ/9hQWFgJAr8Yfp8r3UUZGBqxWK8aOHYuEhASsWbMGTU1NmD17ttKhuZzFixdj2rRpiIiIwOnTp5GVlQWdTocZM2YoHZrqNTY2yn6pKy8vR2FhIQICAjBkyBAsWrQIr7/+OqKjoxEZGYnMzEyEhYUhJSVFuaBV7Eb9GRAQgBUrViA1NRUmkwllZWVYsmQJoqKikJSUpGDU6pSWloacnBx8/vnn8PHxkdbA+fn5wWAwwM/PD3PmzEFGRgYCAgLg6+uLBQsWIDExEePHj1c4eqJOzPWOYX7vHeZ0xzCH9x1ztmNu1n9lZWXIycnBo48+isDAQPz4449IT0/HAw88gFGjRvX8gxy6J30/984774ghQ4YIT09PkZCQIA4cOKB0SC5p+vTpwmw2C09PTzFo0CAxffp0UVpaqnRYLmHXrl0CQJfNarUKITofH5OZmSlCQ0OFXq8XkyZNEiUlJcoGrWI36s/m5mYxZcoUERwcLDw8PERERIR4/vnnRVVVldJhq5K9fgQgPvjgA+mYixcvihdffFH4+/sLLy8v8cQTT4jKykrlgiayg7m+75jfe4c53THM4X3HnO2Ym/VfRUWFeOCBB0RAQIDQ6/UiKipKvPzyy6Kurq5Xn6O5/GFEREREREREpEJc405ERERERESkYizciYiIiIiIiFSMhTsRERERERGRirFwJyIiIiIiIlIxFu5EREREREREKsbCnYiIiIiIiEjFWLgTERERERERqRgLdyIiIiIiIiIVY+FORHadPHkSGo0GhYWFt+wzZs2ahZSUlFvWPhEREV3F3E7kuli4E7mpWbNmQaPRdNmSk5N7dH54eDgqKysxcuTIWxwpERER9QRzO1H/NUDpAIjo1klOTsYHH3wg26fX63t0rk6ng8lkuhVhERERUR8xtxP1T7ziTuTG9Ho9TCaTbPP39wcAaDQarFu3DlOnToXBYMCwYcPw6aefSudeP53uwoULmDlzJoKDg2EwGBAdHS37h8NPP/2EiRMnwmAwIDAwEC+88AIaGxul9zs6OpCRkQGj0YjAwEAsWbIEQghZvDabDdnZ2YiMjITBYEB8fLwsJiIiov7O3XL7zWIgok4s3In6sczMTKSmpuKHH37AzJkz8dRTT6G4uLjbY48ePYqvvvoKxcXFWLduHYKCggAATU1NSEpKgr+/P77//nvk5ubim2++wfz586Xz33rrLXz44Yd4//33sXfvXpw/fx5bt26VfUZ2djY2btyI9evX41//+hfS09Px9NNPY8+ePbeuE4iIiNyIq+X2G8VARNcQROSWrFar0Ol0wtvbW7a98cYbQgghAIi5c+fKzrFYLGLevHlCCCHKy8sFAPHPf/5TCCHEtGnTxOzZs+1+1oYNG4S/v79obGyU9u3YsUNotVpRVVUlhBDCbDaLlStXSu+3t7eLwYMHi8cff1wIIURLS4vw8vIS+/fvl7U9Z84cMWPGjL53BBERkZtwx9x+oxiI6CqucSdyYw8//DDWrVsn2xcQECD9nZiYKHsvMTGx2zvNzps3D6mpqThy5AimTJmClJQU3HvvvQCA4uJixMfHw9vbWzr+vvvug81mQ0lJCQYOHIjKykpYLBbp/QEDBmDs2LHSlLrS0lI0NzfjkUcekX1uW1sb7r777t5/eSIiIjfkbrn9RjEQ0VUs3IncmLe3N6KiopzS1tSpU/HLL7/gyy+/RF5eHiZNmoS0tDS8+eabTmn/ypq5HTt2YNCgQbL3enrTHSIiInfnbrn9VsdA5C64xp2oHztw4ECX17Gxsd0eHxwcDKvVio8++ghr1qzBhg0bAACxsbH44Ycf0NTUJB27b98+aLVaxMTEwM/PD2azGQcPHpTev3TpEgoKCqTXcXFx0Ov1qKioQFRUlGwLDw931lcmIiJya66Y27uLgYiu4hV3IjfW2tqKqqoq2b4BAwZIN33Jzc3F2LFjMWHCBHz88cc4dOgQ3nvvPbttLV++HGPGjMGdd96J1tZWbN++XfqHwMyZM5GVlQWr1YpXX30VZ86cwYIFC/DMM88gNDQUALBw4UL89a9/RXR0NEaMGIHVq1ejtrZWat/HxweLFy9Geno6bDYbJkyYgLq6Ouzbtw++vr6wWq23oIeIiIhci7vl9hvFQERXsXAncmNff/01zGazbF9MTAyOHTsGAFixYgU2b96MF198EWazGZs2bUJcXJzdtjw9PbF06VKcPHkSBoMB999/PzZv3gwA8PLywt///ncsXLgQ48aNg5eXF1JTU7F69Wrp/JdeegmVlZWwWq3QarV47rnn8MQTT6Curk465rXXXkNwcDCys7Nx4sQJGI1G3HPPPVi2bJmzu4aIiMgluVtuv1EMRHSVRojrHrZIRP2CRqPB1q1bkZKSonQoRERE5ATM7UTui2vciYiIiIiIiFSMhTsRERERERGRinGqPBEREREREZGK8Yo7ERERERERkYqxcCciIiIiIiJSMRbuRERERERERCrGwp2IiIiIiIhIxVi4ExEREREREakYC3ciIiIiIiIiFWPhTkRERERERKRiLNyJiIiIiIiIVOz/AaZYhH3cddomAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = env_design.diagnostics[\"parameter_means\"]\n",
    "params = np.array(params)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "roi_sizes = env_design.diagnostics[\"ROI_sizes\"]\n",
    "roi_sizes = np.array(roi_sizes)\n",
    "axs[0].plot(roi_sizes, \"-x\", label=\"ROI Size\")\n",
    "axs[0].set_xlabel(\"Episode\")\n",
    "axs[0].set_ylabel(\"Size of ROI\")\n",
    "axs[0].set_ylim(0,1)\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Size of ROI over time when learning R and $\\gamma$\")\n",
    "\n",
    "axs[1].plot(params[:, 0], color=\"orange\", label=\"Estimated gamma\")\n",
    "axs[1].plot(params[:, 1], color=\"blue\", label=\"Estimated p\")\n",
    "axs[1].hlines(true_params.gamma, 0, params.shape[0], color=\"orange\", linestyle=\"--\", label=\"True Gamma\")\n",
    "axs[1].hlines(true_params.T, 0, params.shape[0], color=\"blue\", linestyle=\"--\", label=\"True p\")\n",
    "axs[1].set_ylim(0,1)\n",
    "axs[1].set_title(\"Parameter Estimates over Time, Cliff World\")\n",
    "axs[1].set_xlabel(\"Episodes\")\n",
    "axs[1].set_ylabel(\"Parameter Value\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all_params = []\n",
    "all_params.append(p_range)\n",
    "all_params.append(gamma_range)\n",
    "\n",
    "a = np.array(all_params)\n",
    "\n",
    "# parameter_mesh = []\n",
    "# for param in itertools.product(*all_params):\n",
    "    # print(param)\n",
    "    # parameter_mesh.append((param[0][0], param[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameter_mesh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparameter_mesh\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameter_mesh' is not defined"
     ]
    }
   ],
   "source": [
    "parameter_mesh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
